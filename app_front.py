# -*- coding: utf-8 -*-
# File: app.py
# Description: Multi-user Airfoil Design Assistant (Windows + Admin Panel)

import streamlit as st
import streamlit.components.v1 as components
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable
from langchain.memory import ConversationBufferMemory

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import shutil, subprocess, tempfile, os, requests
import re, html
import json






# ===== Config =====
BACKEND_URL = os.getenv("BACKEND_URL", "http://139.196.12.84:8000")
ADMIN_PASS = os.getenv("ADMIN_PASS", "ecnustju")

import os
os.environ["OPENAI_API_KEY"] = "sk-ä½ çš„key"

# =========================
# â€”â€” XFOIL Wrapper (Windows) â€”â€”
# =========================
try:
    from xfoil import XFoil
    from xfoil.model import Airfoil
    XFOIL_PY_OK = True
except Exception:
    XFOIL_PY_OK = False


# =========================
# â€”â€” XFOIL Wrapper (Windows ä¸“ç”¨) â€”â€”
# =========================

def _which_xfoil():
    """åªåœ¨å½“å‰ç›®å½•ä¸‹æŸ¥æ‰¾ xfoil.exe"""
    exe_path = os.path.join(os.getcwd(), "xfoil.exe")
    if os.path.exists(exe_path):
        return exe_path
    raise FileNotFoundError(" æ²¡æœ‰æ‰¾åˆ° xfoil.exeï¼Œè¯·ç¡®è®¤å®ƒåœ¨ bot-remote-windows ç›®å½•ä¸‹")

def run_xfoil_cli_polar(naca_code: str, Re: float, Mach: float, Ncrit: float,
                        alpha_start: float, alpha_end: float, alpha_step: float) -> pd.DataFrame:
    exe = os.path.abspath("xfoil.exe")  # âœ… å¼ºåˆ¶ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ xfoil.exe
    if not os.path.exists(exe):
        print(" xfoil.exe not found in", exe)
        return pd.DataFrame(columns=["alpha", "CL", "CD", "CM"])

    with tempfile.TemporaryDirectory() as td:
        pol_path = os.path.join(td, "polar.out")

        # âœ… è¾“å…¥è„šæœ¬ï¼ˆä¸¥æ ¼æŒ‰ç…§ Windows ç‰ˆ XFOIL è¦æ±‚ï¼‰
        script = f"""
NACA {naca_code}
PANE
OPER
VISC {Re:.3e}
MACH {Mach:.4f}
VPAR
N {int(Ncrit)}

PACC
{pol_path}

ASEQ {alpha_start:.1f} {alpha_end:.1f} {alpha_step:.1f}
PACC

QUIT
"""

        # âœ… åœ¨å½“å‰ç›®å½•è¿è¡Œï¼ˆé¿å… exe æ‰¾ä¸åˆ°ï¼‰
        result = subprocess.run(
            [exe],
            input=script,
            text=True,
            capture_output=True,
            cwd=os.getcwd(),
            timeout=60
        )

        # è°ƒè¯•è¾“å‡ºï¼ˆåªçœ‹å‰ 400 å­—ç¬¦ï¼‰
        print("=== XFOIL STDOUT ===\n", (result.stdout or "")[:400])
        print("=== XFOIL STDERR ===\n", (result.stderr or "")[:400])

        if not os.path.exists(pol_path):
            print(" polar.out not generated")
            return pd.DataFrame(columns=["alpha", "CL", "CD", "CM"])

        # âœ… è§£æ polar.out
        rows = []
        with open(pol_path, "r") as f:
            for line in f:
                if ("alpha" in line and "CL" in line and "CD" in line) or set(line.strip()) <= set("-= "):
                    continue
                parts = line.strip().split()
                if len(parts) >= 5:
                    try:
                        a = float(parts[0])
                        cl = float(parts[1])
                        cd = float(parts[2])
                        cm = float(parts[4])
                        rows.append((a, cl, cd, cm))
                    except Exception:
                        continue

        if not rows:
            print(" polar.out parsed but empty")
            return pd.DataFrame(columns=["alpha", "CL", "CD", "CM"])

        return pd.DataFrame(rows, columns=["alpha", "CL", "CD", "CM"]).sort_values("alpha").reset_index(drop=True)

@st.cache_data(show_spinner=True)
def run_xfoil_polar(naca_code: str, Re: float, Mach: float, Ncrit: float,
                    alpha_start: float, alpha_end: float, alpha_step: float) -> pd.DataFrame:
    if XFOIL_PY_OK:
        try:
            af = Airfoil.NACA(naca_code)
            xf = XFoil()
            xf.airfoil = af
            xf.Re = max(Re, 1e4)
            xf.M = max(Mach, 0.0)
            xf.n_crit = Ncrit
            try:
                a, cl, cd, cm, _ = xf.aseq(alpha_start, alpha_end, alpha_step)
            except Exception:
                A = np.arange(alpha_start, alpha_end + 1e-9, alpha_step)
                alist, clist, cdlist, cmlist = [], [], [], []
                for a0 in A:
                    try:
                        cl0, cd0, cm0, _cp = xf.a(a0)
                        alist.append(a0); clist.append(cl0); cdlist.append(cd0); cmlist.append(cm0)
                    except Exception:
                        continue
                a = np.array(alist); cl = np.array(clist); cd = np.array(cdlist); cm = np.array(cmlist)
            mask = np.isfinite(a) & np.isfinite(cl) & np.isfinite(cd) & np.isfinite(cm)
            df = pd.DataFrame({"alpha": a[mask], "CL": cl[mask], "CD": cd[mask], "CM": cm[mask]})
            df = df.sort_values("alpha").reset_index(drop=True)
            if not df.empty:
                return df
        except Exception:
            pass
    return run_xfoil_cli_polar(naca_code, Re, Mach, Ncrit, alpha_start, alpha_end, alpha_step)


def fallback_fake_polar(alpha_start, alpha_end, alpha_step):
    alphas = np.arange(alpha_start, alpha_end + 1e-9, alpha_step)
    CL = 0.1 * alphas
    CD = 0.01 + 0.002 * alphas**2
    CM = -0.05 * np.ones_like(alphas)
    return pd.DataFrame({"alpha": alphas, "CL": CL, "CD": CD, "CM": CM})


# =========================
# â€”â€” LangGraph + ChatGPTï¼ˆä¿®å¤ç‰ˆï¼‰ â€”â€”
# =========================
import os
from langchain_openai import ChatOpenAI

# typing å…¼å®¹å¯¼å…¥
try:
    from typing import TypedDict, Dict, Any
except ImportError:            # < Py3.8 æ‰ä¼šèµ°åˆ°è¿™é‡Œ
    from typing_extensions import TypedDict
    from typing import Dict, Any

llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.2,
    api_key="sk-VrwOEEFLgjJwSOjH5pHRTDorgf0SmJVQrjK2D1uyjxZcfsrn",   # å†™åœ¨è¿™é‡Œ
    base_url="http://49.51.37.239:3006/v1"  # ä¸­è½¬åœ°å€
)
memory = ConversationBufferMemory(memory_key="history")

roles = {
    "Concept Learning": (
        "You are an AI tutor specialized in **conceptual learning**. "
        "Your role is to guide students in breaking down abstract fluid mechanics concepts "
        "into smaller, teachable parts. "
        "You should always respond in English with a **guiding and questioning tone**, "
        "encouraging the student to reflect. "
        "Never give the final answer directly. "
        "Ask questions such as: 'Which factors do you think are important, and why?' "
        "or 'How would changing the camber affect the lift coefficient?'"
    ),
    "Model Iteration": (
        "You are an AI assistant specialized in **model iteration and experiment design**. "
        "Your role is to help students analyze simulation data, propose adjustments, "
        "and suggest possible experiment setups. "
        "Always respond in English with a **coaching style**, focusing on reasoning and exploration, "
        "rather than giving direct solutions. "
        "Encourage the student to test ideas and compare results, for example: "
        "'What would happen if you increased the Reynolds number?' "
        "or 'How could you verify whether thickness has a stronger impact than camber?'"
    ),
    "Strategy Review": (
        "You are an AI mentor specialized in **strategy review and reflection**. "
        "Your role is to evaluate the studentâ€™s current approach and give constructive feedback "
        "on their design strategies. "
        "Always respond in English with a **critical but supportive tone**, "
        "pointing out strengths and possible improvements. "
        "Do not just state the answer â€” instead, highlight gaps and suggest next steps. "
        "For example: 'Your strategy improves L/D ratio, but it may ignore stall effects. "
        "What adjustment could account for that?'"
    )
}

role_guides = {
    "Concept Learning": [
        "Break down the key sub-concepts of 'Lift Coefficient' into a 3-level teachable structure.",
        "Based on C-K theory, propose 3 concept-to-concept expansion paths, each with an engineering context."
    ],
    "Model Iteration": [
        "Design a reproducible experiment to compare two airfoils at Re=3e5 (include variables and indicators).",
        "Provide suggestions for XFOIL polar scan parameter settings and explain the rationale for Ncrit values."
    ],
    "Strategy Review": [
        "Check the logic of this argument about lift-to-drag ratio, and point out gaps in claimâ€“evidenceâ€“warrant chain.",
        "Give 3 rewriting suggestions to make the argument more academic and evidence-complete."
    ]
}

role_descriptions = {
    "Concept Learning": "Focus on clarifying core concepts.",
    "Model Iteration": "Assist with experiments and parameter tuning.",
    "Strategy Review": "Give feedback on strategies and reasoning."
}

def get_prompt(role):
    return ChatPromptTemplate.from_messages([
        ("system", roles[role] + "\nHistorical Dialogue: {history}"),
        ("user", "{question}")
    ])

# ---- State ç±»å‹ï¼ˆdict å½¢å¼ï¼ŒLangGraph æ¨èï¼‰----
class GraphState(TypedDict, total=False):
    role: str
    history: str
    question: str
    content: str   # ç”±èŠ‚ç‚¹å†™å›

# ---- å°†æ¯ä¸ªè§’è‰²å°è£…ä¸ºè¿”å› dict çš„èŠ‚ç‚¹ ----
def create_node(role: str):
    prompt = get_prompt(role)
    chain = prompt | llm

    def _run(state: GraphState) -> Dict[str, Any]:
        res = chain.invoke({
            "history": state.get("history", ""),
            "question": state.get("question", "")
        })
        text = getattr(res, "content", str(res))
        return {"content": text}   # âœ… å†™å›åˆ°çŠ¶æ€
    return _run

graph = StateGraph(GraphState)
for r in roles:
    graph.add_node(r, create_node(r))

# ---- æ¡ä»¶è·¯ç”±ï¼šå‡½æ•°åªè¿”å›â€œä¸‹ä¸€èŠ‚ç‚¹åâ€ï¼Œä¸è¦å½“èŠ‚ç‚¹æœ¬èº«è¿”å› ----
def route_role(state: GraphState) -> str:
    return state["role"]

# ğŸš© router èŠ‚ç‚¹å¿…é¡»è¿”å› dictï¼Œè¿™é‡Œç”¨ç©ºæ“ä½œå ä½
graph.add_node("router", lambda state: {})   # âœ… ä¸è¦è¿”å›å­—ç¬¦ä¸²ï¼
graph.set_entry_point("router")
graph.add_conditional_edges("router", route_role, {r: r for r in roles})

for r in roles:
    graph.add_edge(r, END)

app = graph.compile()
# >>> PATCH: LLM retry helper (place right after `app = graph.compile()`)
import time as _t

def call_llm_with_retries(state: dict, retries: int = 3, base_delay: float = 2.0) -> str:
    """
    Call the LangGraph app with simple exponential backoff.
    Returns the LLM text or "" if all attempts failed or empty.
    """
    last_err = None
    for k in range(retries):
        try:
            resp_state = app.invoke(state)
            txt = (resp_state or {}).get("content", "")
            if isinstance(txt, str) and txt.strip():
                return txt.strip()
        except Exception as e:
            last_err = e
        # backoff: 2s, 4s, 8s ...
        _t.sleep(base_delay * (2 ** k))
    # all failed or got empty content
    if last_err:
        # è®©è°ƒç”¨æ–¹å†³å®šæ˜¯å¦å±•ç¤ºé”™è¯¯/è½ç›˜
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›ç©ºä¸²ä»¥èµ°ç»Ÿä¸€å…œåº•æç¤º
        pass
    return ""

# ==== Stream Chat (OpenAI-compatible, via SSE) ====
OPENAI_BASE_URL = "http://49.51.37.239:3006/v1"  # ä¸ä½ ä¸Šé¢ llm çš„ base_url ä¸€è‡´
OPENAI_API_KEY  = "sk-VrwOEEFLgjJwSOjH5pHRTDorgf0SmJVQrjK2D1uyjxZcfsrn"  # ä¸ä½ ä¸Šé¢ llm çš„ api_key ä¸€è‡´

def stream_chat_completions(messages, model="gpt-4o", temperature=0.2, timeout=60):
    """
    ç›´æ¥è°ƒç”¨ OpenAI å…¼å®¹æ¥å£è¿›è¡Œæµå¼è¾“å‡ºï¼ˆSSEï¼‰ã€‚yield æ¯ä¸ªæ–°å¢çš„ content ç‰‡æ®µï¼ˆå¯èƒ½ä¸ºç©ºä¸²ï¼‰ã€‚
    messages: [{"role":"system","content":...}, {"role":"user","content":...}, ...]
    """
    import requests, json
    url = f"{OPENAI_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "temperature": float(temperature),
        "stream": True,
        "messages": messages
    }
    with requests.post(url, headers=headers, json=payload, stream=True, timeout=timeout) as r:
        r.raise_for_status()
        for line in r.iter_lines(decode_unicode=True):
            if not line:
                continue
            if line.startswith("data:"):
                data = line[len("data:"):].strip()
                if data == "[DONE]":
                    break
                try:
                    obj = json.loads(data)
                    delta = obj["choices"][0]["delta"]
                    yield delta.get("content", "")
                except Exception:
                    # å¿½ç•¥æ— æ³•è§£æçš„ç‰‡æ®µ
                    continue



# =========================
# â€”â€” Geometry Utils â€”â€”
# =========================
@st.cache_data(show_spinner=False)
def gen_naca4(m: float, p: float, t: float, n_pts: int = 200):
    x = np.linspace(0, 1, n_pts)
    yt = 5 * t * (
        0.2969 * np.sqrt(np.clip(x, 1e-12, 1.0))
        - 0.1260 * x - 0.3516 * x**2 + 0.2843 * x**3 - 0.1015 * x**4
    )
    p_eps = max(p, 1e-12); q_eps = max(1-p, 1e-12)
    yc = np.where(x < p,
        (m/(p_eps**2))*(2*p*x - x**2),
        (m/(q_eps**2))*((1-2*p) + 2*p*x - x**2)
    )
    dyc_dx = np.where(x < p,
        (2*m/(p_eps**2))*(p - x),
        (2*m/(q_eps**2))*(p - x)
    )
    theta = np.arctan(dyc_dx)
    xu = x - yt*np.sin(theta); yu = yc + yt*np.cos(theta)
    xl = x + yt*np.sin(theta); yl = yc - yt*np.cos(theta)
    xs = np.concatenate([xl[::-1], xu[1:]])
    ys = np.concatenate([yl[::-1], yu[1:]])
    return xs, ys


def naca_code_from_mpt(m: float, p: float, t: float) -> str:
    m_pct = int(round(m*100)); p_tenths = int(round(p*10)); t_pct = int(round(t*100))
    return f"{m_pct}{p_tenths}{t_pct:02d}"


def estimate_Re(rho: float, V: float, chord: float, mu: float) -> float:
    return (rho*V*chord)/max(mu, 1e-9)


# =====================
# â€”â€” Streamlit UI â€”â€”
# =====================
st.set_page_config(page_title="Fluid Mechanics AI Assistant", layout="wide")
# --- åˆå¹¶ä¸”åŠ å›ºçš„æ ·å¼ï¼ˆåªä¿ç•™è¿™ä¸€ä¸ª <style>ï¼‰ ---
st.markdown("""
<style>
/* 1) è®©ä¸»å®¹å™¨é¡¶éƒ¨æœ‰å……è¶³ç•™ç™½ï¼Œé¿å…è¢«å›ºå®šå¤´éƒ¨è¦†ç›– */
.block-container {
    padding-top: 2.0rem !important;   /* å»ºè®® â‰¥1.6remï¼›è‹¥ä»è¢«é®æŒ¡ï¼Œè°ƒåˆ° 2.4rem */
    padding-bottom: 0.8rem !important;
    overflow: visible !important;      /* é˜²æ­¢è¢«è£åˆ‡ */
}

/* 2) ä¿è¯æ ‡é¢˜æœ¬èº«ä¸è¢«æŒ¤ï¼›è¡Œé«˜å……è¶³ã€å¤–è¾¹è·åˆç† */
h1 {
    margin: 0 0 .6rem 0 !important;
    line-height: 1.18 !important;
    word-break: break-word;
}

/* 3) æœ‰äº›é¡¹ç›®é‡Œä¼šç»™ header/å®¹å™¨è®¾ç½® overflow:hiddenï¼Œè¿™é‡Œå¼ºåˆ¶è§£é™¤ */
header, [data-testid="stHeader"] {
    overflow: visible !important;
}

/* 4) æ¬¡çº§æ ‡é¢˜æ›´ç´§å‡‘ï¼ˆå¯é€‰ï¼‰ */
h3, h4, h5 { margin: .2rem 0 .2rem 0 !important; }

/* 5) ä¸è¦ç”¨ä¼šå˜åŠ¨çš„æƒ…ç»ªç±»åï¼Œä»¥ä¸‹ä»…å¯¹å¸¸ç”¨æ§ä»¶è½»é‡æ”¶ç´§ï¼ˆå¯é€‰ï¼‰ */
div[data-testid="stSlider"], div[data-testid="stNumberInput"] { margin-bottom: .35rem; }

/* 6) å³ä¾§è¾“å…¥è¡Œå¾®è°ƒï¼ˆå¯é€‰ï¼‰ */
.input-row { margin-top: .4rem; }

</style>
""", unsafe_allow_html=True)
st.markdown("""
<style>
/* Top-anchored, no vertical blank area for matplotlib images/canvas */
.fixed-plot {
  height: 320px;                /* ä½ ä¹Ÿå¯ä»¥æ”¹æˆ 300/340ï¼›å›ºå®šé«˜åº¦ï¼Œé¿å…è·³åŠ¨ */
  position: relative;
  overflow: hidden;
}

/* è®©å›¾ç‰‡/ç”»å¸ƒé“ºæ»¡å®¹å™¨ï¼Œé«˜åº¦ä¼˜å…ˆï¼Œä¿æŒç­‰æ¯”ï¼Œä¸å†å±…ä¸­ */
.fixed-plot img, .fixed-plot canvas {
  position: absolute;
  inset: 0;                     /* top:0 right:0 bottom:0 left:0 */
  width: 100%;
  height: 100%;
  object-fit: contain;          /* ä¿æŒç­‰æ¯” */
  object-position: top left;    /* é¡¶å¯¹é½ï¼ˆä¹Ÿå¯ç”¨ 'top center'ï¼‰*/
  display: block;               /* å»æ‰ inline å…ƒç´ é€ æˆçš„å‚ç›´å¯¹é½å½±å“ */
}
</style>
""", unsafe_allow_html=True)


st.title("AI-Enhanced Airfoil Design & Learning Lab")
st.caption("An AI-powered airfoil design assistant for NACA geometry preview, XFOIL polar analysis, and role-based learning guidance.")

# ==== Sidebar: User / Admin Login ====
st.sidebar.title("Login")
user_id = st.sidebar.text_input("Enter your User ID", value="guest")
st.sidebar.markdown("---")
st.sidebar.subheader("Admin Access")
admin_password = st.sidebar.text_input("Enter admin password", type="password")
is_admin = (admin_password == ADMIN_PASS)

# ==== Session init ====
if "param_history" not in st.session_state:
    st.session_state.param_history = []
if "prev_role" not in st.session_state:
    st.session_state.prev_role = None

# âœ… æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„èŠå¤©è®°å½•
chat_key = f"chat_history_{user_id}"
if chat_key not in st.session_state:
    st.session_state[chat_key] = []

# ==== Layout ====
col_chat, col_main = st.columns([1, 1], gap="large")

import time

# ===== Left: Dialogue =====
with col_chat:
    # ï¼ˆä¸è¦æ ‡é¢˜äº†ï¼‰
    # === æ ·å¼å®šä¹‰ ===
    st.markdown(
        """
        <style>
        .chat-wrapper {
            background-color: #f5f5f5;
            padding: 12px;
            border-radius: 10px;
            height: 55vh;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
        }
        .bubble {
            max-width: 75%;
            padding: 8px 12px;
            margin: 6px;
            border-radius: 8px;
            word-wrap: break-word;
            font-size: 14px;
            line-height: 1.4;
        }
        .user-bubble {
            background-color: #95ec69;
            margin-left: auto;
            text-align: right;
        }
        .ai-bubble {
            margin-right: auto;
            text-align: left;
        }
        .concept { background-color: #d0e6ff; }
        .model { background-color: #ffe4b3; }
        .strategy { background-color: #e6ccff; }
        .system {
            color: #555;
            text-align: center;
            font-size: 13px;
            font-style: italic;
            margin: 4px 0;
        }
        /* æŒ‰é’®ç»Ÿä¸€æ ·å¼ */
        div[data-testid="stButton"] button {
            background-color: #4da6ff;
            color: white;
            border-radius: 6px;
            padding: 0.3em 0.6em;
            font-size: 14px;
            border: none;
        }
        div[data-testid="stButton"] button:hover {
            background-color: #1a8cff;
            color: white;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )



    st.markdown(
        """
        <style>
        /* â€”â€” ç´§å‡‘ï¼šcomponents.html/æœç´¢/æŒ‰é’® â€”â€” */
        .ctl-label { font-size: 0.82rem; color:#444; margin:0 0 4px 2px; }
        div[data-testid="stMultiSelect"] > div { margin-bottom: 0.2rem; }
        div[data-baseweb="select"] { min-height: 34px; }
        div[data-baseweb="select"] > div { min-height: 34px; padding-top: 2px; padding-bottom: 2px; }
        div[data-baseweb="tag"] { margin: 2px 4px; transform: scale(0.92); }
        div[data-testid="stTextInput"] input { height: 34px; padding: 2px 8px; font-size: 0.90rem; }
        div[data-testid="stTextInput"] label { margin-bottom: 4px; font-size: 0.82rem; }
        .small-btn button { height: 34px; padding: 0 10px; font-size: 0.90rem; border-radius: 8px; }
        .compact-row { margin-bottom: 0.25rem; }
        
        </style>
        """,
        unsafe_allow_html=True,
    )

    # === æ¢å¤å†å²æŒ‰é’® ===
    if st.button("ğŸ“œ Restore historical dialogue", use_container_width=True):
        try:
            resp = requests.get(f"{BACKEND_URL}/export_conversations/{user_id}", timeout=10)
            if resp.status_code == 200:
                history_data = resp.json()
                history_data = sorted(history_data, key=lambda x: x["timestamp"])
                past_msgs = []
                if history_data:
                    past_msgs.append({"role": "system", "content": "â€”â€” ğŸ•’ Historical Dialogue â€”â€”"})
                    for h in history_data:
                        if h.get("student_question"):
                            past_msgs.append({"role": "user", "content": h["student_question"]})
                        if h.get("ai_response"):
                            past_msgs.append({
                                "role": "ai",
                                "content": h["ai_response"],
                                "module": h.get("role", "AI")
                            })
                st.session_state[chat_key] = past_msgs  # âœ… è¦†ç›–
                st.success("âœ… History has been rewritten")
                st.session_state["force_scroll_bottom"] = True  # âœ… æ¢å¤åå¼ºåˆ¶åˆ°åº•
            else:
                st.info("â„¹ï¸ No historical records were found")
        except Exception as e:
            st.error(f" Error fetching history: {e}")

    # === æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„èŠå¤© key ===
    chat_key = f"chat_history_{user_id}"
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []

    # === æ»šåŠ¨ä¸æœç´¢çš„ session çŠ¶æ€ ===
    if "force_scroll_bottom" not in st.session_state:
        st.session_state["force_scroll_bottom"] = False
    if "scroll_to_msg_id" not in st.session_state:
        st.session_state["scroll_to_msg_id"] = ""
    if "chat_search_q" not in st.session_state:
        st.session_state["chat_search_q"] = ""
    if "search_hits" not in st.session_state:
        st.session_state["search_hits"] = []
    if "search_pos" not in st.session_state:
        st.session_state["search_pos"] = 0
    if "chat_filter_roles" not in st.session_state:
        st.session_state["chat_filter_roles"] = list(roles.keys())  # é»˜è®¤å…¨é€‰

    # === ç­›é€‰ + æœç´¢æ§ä»¶ï¼ˆåŒåˆ—å¸ƒå±€ï¼šå·¦ç­›é€‰ / å³æœç´¢+æŒ‰é’®ï¼‰===
    st.markdown("""
    <style>
      /* å³ä¾§æŒ‰é’®ï¼šä¿è¯æ¨ªå‘æ˜¾ç¤ºå¹¶ä¸æŠ˜è¡Œ */
      .small-btn button {
        height: 28px;          /* å‡å°æŒ‰é’®é«˜åº¦ */
        padding: 0 10px;       /* å‡å°å†…è¾¹è· */
        font-size: 0.85rem;    /* ç¨å¾®å‡å°å­—ä½“ */
        border-radius: 6px;
        white-space: nowrap;
        min-width: 80px;
      }
      .ctrl-group { 
        margin-top: 0.1rem;    /* å‡å°å‚ç›´é—´è· */
        margin-bottom: 0.1rem;
      }
      /* æ ‡ç­¾æ›´ç´§å‡‘ */
      .ctl-label { 
        font-size: 0.82rem; 
        color:#bbb; 
        margin: 0 0 3px 2px;   /* å‡å°æ ‡ç­¾åº•éƒ¨é—´è· */
      }
      /* è¾“å…¥æ¡†æ›´çŸ®ä¸€äº› */
      div[data-testid="stTextInput"] input { 
        height: 32px;          /* å‡å°æœç´¢æ¡†é«˜åº¦ */
        padding: 3px 8px; 
        font-size: 0.9rem; 
      }
      div[data-testid="stMultiSelect"] > div { margin-bottom: 0.2rem; }
      div[data-baseweb="select"] { min-height: 32px; }  /* åŒ¹é…æœç´¢æ¡†é«˜åº¦ */
      div[data-baseweb="select"] > div { 
        min-height: 32px; 
        padding-top: 1px; 
        padding-bottom: 1px; 
      }
      div[data-baseweb="tag"] { 
        margin: 1px 3px; 
        transform: scale(0.9); /* ç¨å¾®ç¼©å°æ ‡ç­¾ */
      }
    </style>
    """, unsafe_allow_html=True)

    ctl_left, ctl_right = st.columns([1, 1], gap="small")

    # å·¦ä¾§ï¼šæ¨¡å—ç­›é€‰ï¼ˆä¿æŒä¸å˜ï¼‰
    with ctl_left:
        st.markdown('<div class="ctl-label">Filter modules</div>', unsafe_allow_html=True)
        st.session_state["chat_filter_roles"] = st.multiselect(
            label="Filter modules",
            options=list(roles.keys()),
            default=st.session_state["chat_filter_roles"],
            help="ç­›é€‰æ˜¾ç¤ºä¸åŒ AI æ¨¡å—çš„æ¶ˆæ¯ï¼ˆç”¨æˆ·æ¶ˆæ¯å§‹ç»ˆæ˜¾ç¤ºï¼‰",
            label_visibility="collapsed"
        )

    # å³ä¾§ï¼šæœç´¢ + æŒ‰é’®ï¼ˆä¼˜åŒ–å¸ƒå±€ï¼‰
    with ctl_right:
        st.markdown('<div class="ctl-label">Search history</div>', unsafe_allow_html=True)
        q = st.text_input(
            "Search history",
            value=st.session_state["chat_search_q"],
            placeholder="Enter keywords; Use Prev/Next to jump",
            key="chat_search_q",
            label_visibility="collapsed",
        ).strip()

        # Prev / Next / Latest æŒ‰é’®æ”¾åœ¨åŒä¸€è¡Œ
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1.2], gap="small")

        with col_btn1:
            st.markdown('<div class="small-btn ctrl-group">', unsafe_allow_html=True)
            btn_prev = st.button("Prev", use_container_width=True, key="btn_prev")
            st.markdown('</div>', unsafe_allow_html=True)

        with col_btn2:
            st.markdown('<div class="small-btn ctrl-group">', unsafe_allow_html=True)
            btn_next = st.button("Next", use_container_width=True, key="btn_next")
            st.markdown('</div>', unsafe_allow_html=True)

        with col_btn3:
            st.markdown('<div class="small-btn ctrl-group">', unsafe_allow_html=True)
            btn_jump_latest = st.button("â¬‡ï¸ Latest", use_container_width=True, key="btn_latest")
            st.markdown('</div>', unsafe_allow_html=True)

    if btn_jump_latest:
        st.session_state["force_scroll_bottom"] = True

    # === æ„å»ºâ€œæ˜¾ç¤ºåˆ—è¡¨â€çš„ç´¢å¼•ï¼ˆæŒ‰æ¨¡å—è¿‡æ»¤ï¼Œåªæ˜¾ç¤ºâ€œAI(é€‰ä¸­æ¨¡å—)+å®ƒå‰é¢çš„å­¦ç”Ÿé—®â€ï¼‰ ===
    messages = st.session_state[chat_key]
    allowed = set(st.session_state["chat_filter_roles"])

    display_indices = []
    n = len(messages)


    def include_pair(ai_idx: int):
        """æŠŠ ai_idx åŠå…¶å‰é¢çš„æœ€è¿‘ä¸€æ¡ user åŠ å…¥æ˜¾ç¤º"""
        if 0 <= ai_idx < n and ai_idx not in display_indices:
            display_indices.append(ai_idx)
        # å¯»æ‰¾ ai ä¹‹å‰æœ€è¿‘çš„ä¸€æ¡ user
        j = ai_idx - 1
        while j >= 0 and messages[j]["role"] == "system":
            j -= 1
        if j >= 0 and messages[j]["role"] == "user" and j not in display_indices:
            display_indices.append(j)


    # 1) æ”¶é›†ç¬¦åˆæ¨¡å—çš„ AI å›å¤ä¸å…¶å‰é¢çš„ user
    for i, msg in enumerate(messages):
        if msg["role"] in ("ai", "ai_stream"):
            module = msg.get("module", "AI")
            if module in allowed:
                include_pair(i)

    # 2) å¦‚æœæœ€åä¸€æ¡æ˜¯â€œç”¨æˆ·åˆšå‘çš„æ¶ˆæ¯â€ï¼ˆå¯èƒ½è¿˜æ²¡æ”¶åˆ° AIï¼‰ï¼Œä¹Ÿæ˜¾ç¤ºå®ƒ
    if n > 0 and messages[-1]["role"] == "user":
        if (n - 1) not in display_indices:
            display_indices.append(n - 1)

    # 3) æ’åºä¿æŒæ—¶é—´é¡ºåº
    display_indices.sort()

    # === è®¡ç®—æœç´¢å‘½ä¸­ï¼ˆä»…åœ¨â€œæ˜¾ç¤ºåˆ—è¡¨â€å†…æœç´¢ï¼‰ ===
    hits = []
    if q:
        q_lower = q.lower()
        for i in display_indices:
            content = str(messages[i].get("content", ""))
            if q_lower in content.lower():
                hits.append(i)

    # === å¤„ç† Next/Prev å¯¼èˆª ===
    if hits:
        if btn_next:
            st.session_state["search_pos"] = (st.session_state.get("search_pos", 0) + 1) % len(hits)
            st.session_state["scroll_to_msg_id"] = f"msg-{hits[st.session_state['search_pos']]}"
        if btn_prev:
            st.session_state["search_pos"] = (st.session_state.get("search_pos", 0) - 1) % len(hits)
            st.session_state["scroll_to_msg_id"] = f"msg-{hits[st.session_state['search_pos']]}"

    # å‘½ä¸­è®¡æ•°æç¤º
    if q:
        if hits:
            pos = (st.session_state.get('search_pos', 0) % len(hits)) + 1 if len(hits) else 0
            st.caption(f"ğŸ” Found {len(hits)} hit(s) â€” {pos}/{len(hits)}")
        else:
            st.caption("ğŸ” No hits")

     # --- holder: the same iframe will be redrawn during streaming ---
    chat_iframe_holder = st.empty()
    CHAT_HEIGHT = 500
    # âš ï¸ Streamlit ä¼šåœ¨ä»»æ„æ§ä»¶å˜åŠ¨åæ•´ä½“ rerunï¼Œæ–°çš„ placeholder
    # æ˜¯ç©ºçš„ã€‚å¦‚æœæˆ‘ä»¬ä»…ä¾èµ– last_chat_doc_sigï¼Œåˆ™å› ä¸ºç­¾åæœªå˜
    # ä¼šè·³è¿‡é¦–æ¬¡æ¸²æŸ“ï¼Œå¯¼è‡´èŠå¤©æ¡†çœ‹èµ·æ¥è¢«â€œåˆ·æ‰â€ã€‚å› æ­¤æ¯æ¬¡ rerun
    # åé‡ç½®ä¸€ä¸ªæ ‡è®°ï¼Œç¡®ä¿é¦–å¸§ä¸€å®šä¼šå†™å…¥ iframeã€‚
    st.session_state["_chat_iframe_ready"] = False


    def render_chat_box(messages, q, *, force=False, target_id="", stream=False):
        """
        é‡ç»˜èŠå¤© iframeã€‚
        - ä»…æ˜¾ç¤ºè¢«ç­›é€‰æ¨¡å—çš„ AI/ai_stream + å®ƒå‰ä¸€æ¡ userï¼›è‹¥æœ€åä¸€æ¡æ˜¯ user ä¹Ÿæ˜¾ç¤º
        - æµå¼é˜¶æ®µ (stream=True) å…³é—­é«˜äº®å’Œå®‰å…¨æ¸…æ´—ä»¥æé€Ÿï¼Œæœ€ç»ˆå¸§å†å¼€å¯
        - force=True ä»…ç”¨äºé¦–å¸§æˆ–æœ«å¸§ï¼›ä¸­é—´å¸§ force=Falseï¼Œé…åˆä¸Šæ¸¸èŠ‚æµè°ƒç”¨
        """
        allowed = set(st.session_state["chat_filter_roles"])
        n = len(messages)
        display_indices = []

        def include_pair(ai_idx: int):
            if 0 <= ai_idx < n and ai_idx not in display_indices:
                display_indices.append(ai_idx)
            j = ai_idx - 1
            while j >= 0 and messages[j]["role"] == "system":
                j -= 1
            if j >= 0 and messages[j]["role"] == "user" and j not in display_indices:
                display_indices.append(j)

        # é€‰å–éœ€è¦å±•ç¤ºçš„æ¡ç›®
        for i, msg in enumerate(messages):
            if msg["role"] in ("ai", "ai_stream"):
                module = msg.get("module", "AI")
                if module in allowed:
                    include_pair(i)
        if n > 0 and messages[-1]["role"] == "user":
            if (n - 1) not in display_indices:
                display_indices.append(n - 1)
        display_indices.sort()

        # æœç´¢å‘½ä¸­ï¼ˆæµå¼é˜¶æ®µè·³è¿‡é«˜äº®/å‘½ä¸­è®¡ç®—ï¼‰
        hits = []
        q_norm = (q or "").strip()
        if q_norm and not stream:
            q_lower = q_norm.lower()
            for i in display_indices:
                if q_lower in str(messages[i].get("content", "")).lower():
                    hits.append(i)

        # æ¸²æŸ“ HTMLï¼ˆæµå¼é˜¶æ®µ safe=False ä¸”ä¸é«˜äº®ï¼‰
        inner_html = ""
        for i in display_indices:
            msg = messages[i]
            raw = str(msg.get("content", ""))
            rendered = render_markdown_to_html(raw, safe=not stream)
            content_html = rendered if stream else highlight_after_rendered(rendered, q_norm)

            if msg["role"] == "user":
                inner_html += (
                    f"<div class='bubble user-bubble' id='msg-{i}'>"
                    f"ğŸ‘¤ You ({html.escape(user_id)})<br>{content_html}</div>"
                )
            elif msg["role"] in ("ai", "ai_stream"):
                module = msg.get("module", "AI")
                css_class = {
                    "Concept Learning": "concept",
                    "Model Iteration": "model",
                    "Strategy Review": "strategy"
                }.get(module, "")
                inner_html += (
                    f"<div class='bubble ai-bubble {css_class}' id='msg-{i}'>"
                    f"ğŸ¤– {html.escape(module)}<br>{content_html}</div>"
                )
            elif msg["role"] == "system":
                inner_html += f"<div class='system' id='msg-{i}'>{content_html}</div>"

        FORCE = str(bool(force)).lower()
        TARGET = json.dumps(target_id)

        html_doc = f"""<!DOCTYPE html>
    <html>
    <head>
    <meta charset="utf-8" />
    <style>
      html, body {{
        margin:0; padding:0; height:100%; overflow:hidden;
        font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial;
      }}
      .chat-wrapper {{
        background-color:#f5f5f5; padding:12px; border-radius:10px;
        height:{CHAT_HEIGHT}px; overflow-y:auto; display:flex; flex-direction:column;
        /* ä¸åœ¨å®¹å™¨ä¸Šä½¿ç”¨ smoothï¼Œé¿å…é¢‘ç¹åŠ¨ç”»æŠ–åŠ¨ */
        overscroll-behavior:contain; scrollbar-gutter:stable;
      }}
      .bubble {{
        max-width:75%; padding:8px 12px; margin:6px; border-radius:8px; word-wrap:break-word;
        font-size:14px; line-height:1.4;
      }}
      .user-bubble {{ background-color:#95ec69; margin-left:auto; text-align:right; }}
      .ai-bubble   {{ margin-right:auto; text-align:left; }}
      .concept {{ background-color:#d0e6ff; }}
      .model   {{ background-color:#ffe4b3; }}
      .strategy{{ background-color:#e6ccff; }}
      .system {{ color:#555; text-align:center; font-size:13px; font-style:italic; margin:4px 0; }}
      .hit-focus {{ outline:2px solid #ffb703; transition:outline 1.2s ease-in-out; }}
      mark {{ padding:0 2px; }}
      pre, code {{ font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,monospace; font-size:12.5px; }}
      pre {{ background:#f7f7f9; padding:8px 10px; border-radius:6px; overflow:auto; }}
      table {{ border-collapse:collapse; max-width:100%; }}
      th, td {{ border:1px solid #e5e7eb; padding:4px 8px; font-size:13px; }}
      blockquote {{ border-left:3px solid #e5e7eb; margin:6px 0; padding:4px 8px; color:#444; }}
    </style>
    </head>
    <body>
      <div class="chat-wrapper" id="chat-box">{inner_html}</div>

    <script>
    (function () {{
      const chatBox = document.getElementById('chat-box');
      if (!chatBox) return;

      const FORCE  = {FORCE};
      const TARGET = {TARGET};

      const STORAGE_KEY = "autoFollow:" + {json.dumps(user_id)};
      const SCROLL_KEY  = "scrollTop:"  + {json.dumps(user_id)};

      function getAutoFollow() {{
        const v = localStorage.getItem(STORAGE_KEY);
        return (v === null) ? true : v === "1";
      }}
      function setAutoFollow(on) {{ localStorage.setItem(STORAGE_KEY, on ? "1" : "0"); }}

      function saveScroll() {{
        try {{ sessionStorage.setItem(SCROLL_KEY, String(chatBox.scrollTop)); }} catch (e) {{}}
      }}
      function restoreScroll() {{
        try {{
          const v = sessionStorage.getItem(SCROLL_KEY);
          if (v !== null) {{
            const n = parseInt(v, 10);
            if (!Number.isNaN(n)) chatBox.scrollTop = n;
          }}
        }} catch (e) {{}}
      }}

      function isAtBottom() {{
        return chatBox.scrollTop + chatBox.clientHeight >= chatBox.scrollHeight - 40;
      }}
      function scrollToBottom(force) {{
        if (force || (getAutoFollow() && isAtBottom())) {{
          chatBox.scrollTop = chatBox.scrollHeight; // ç¬æ—¶ç½®åº•
        }}
      }}
      function scrollToTarget(id) {{
        if (!id) return false;
        const el = document.getElementById(id);
        if (el) {{
          el.scrollIntoView({{ behavior: 'auto', block: 'end' }});
          setAutoFollow(false);
          el.classList.add("hit-focus");
          setTimeout(() => el.classList.remove("hit-focus"), 1200);
          return true;
        }}
        return false;
      }}

      // åˆå§‹åŒ–ï¼šä»…åœ¨ FORCE=True æˆ–æœ‰ TARGET æ—¶å¹²é¢„æ»šåŠ¨ï¼›å¦åˆ™å®Œå…¨ä¸åŠ¨å½“å‰æ»šåŠ¨ä½ç½®
requestAnimationFrame(() => setTimeout(() => {{
  if (FORCE) {{
    setAutoFollow(true);
    scrollToBottom(true);   // åªåœ¨æ˜ç¡®è¦æ±‚æ—¶ç½®åº•
  }} else if (TARGET) {{
    scrollToTarget(TARGET); // æœ‰å®šä½ç›®æ ‡æ—¶æ»šåˆ°ç›®æ ‡
  }} // å¦åˆ™ï¼šä¸ restoreã€ä¸ç½®åº•ï¼Œé¿å…åå¤è·³åŠ¨
}}, 0));


      // DOM å˜æ›´ï¼šä»…åœ¨ autoFollow æ—¶ç½®åº•ï¼Œå¹¶ç”¨ rAF åˆå¹¶å¤šæ¬¡å˜æ›´
      let rafId = null;
      const mo = new MutationObserver(() => {{
        if (!getAutoFollow()) return;
        if (rafId) cancelAnimationFrame(rafId);
        rafId = requestAnimationFrame(() => {{
          chatBox.scrollTop = chatBox.scrollHeight;
          rafId = null;
        }});
      }});
      mo.observe(chatBox, {{ childList: true, subtree: true }});

      // ç”¨æˆ·æ»šåŠ¨ï¼šä¸Šæ»šå…³é—­è‡ªåŠ¨è·Ÿéšï¼›åˆ°åº•å¼€å¯
      let lastTop = chatBox.scrollTop;
      chatBox.addEventListener('scroll', () => {{
        saveScroll();
        const nowTop = chatBox.scrollTop;
        const delta  = nowTop - lastTop;
        lastTop = nowTop;
        if (delta < -10) {{
          setAutoFollow(false);
        }} else if (isAtBottom()) {{
          setAutoFollow(true);
        }}
      }});

      window.addEventListener('beforeunload', saveScroll);
    }})();
    </script>
    </body>
    </html>
    """
        # â€”â€” è®¡ç®—è½»é‡ç­¾åï¼šå†…å®¹ + å¼ºåˆ¶æ ‡å¿— + å®šä½ç›®æ ‡ + æ˜¯å¦å¤„äºæµå¼æ¨¡å¼
        doc_sig = hash((inner_html, FORCE, TARGET, bool(stream)))

        # é¦–æ¬¡åˆå§‹åŒ–
        if "last_chat_doc_sig" not in st.session_state:
            st.session_state["last_chat_doc_sig"] = None

        first_frame = not st.session_state.get("_chat_iframe_ready", False)
        if first_frame:
            st.session_state["_chat_iframe_ready"] = True

        # åªæœ‰å†…å®¹å˜åŒ–/é¦–å¸§/force=True æ—¶æ‰é‡ç»˜ iframe
        if force or first_frame or st.session_state["last_chat_doc_sig"] != doc_sig:
            st.session_state["last_chat_doc_sig"] = doc_sig
            with chat_iframe_holder:
                components.html(
                    html_doc,
                    height=CHAT_HEIGHT + 6,
                    scrolling=False,
                )


    # ===== Markdown rendering (server-side) =====
    def render_markdown_to_html(md_text: str, safe=True):
        """safe=True ç”¨ bleachï¼›æµå¼æ—¶ä¼  safe=False ä»¥æé€Ÿ"""
        try:
            import markdown as md
            html_out = md.markdown(md_text, extensions=["fenced_code", "tables", "sane_lists"])
            if safe:
                try:
                    import bleach
                    allowed = bleach.sanitizer.ALLOWED_TAGS.union(
                        {"p", "pre", "code", "table", "thead", "tbody", "tr", "th", "td", "hr",
                         "h1", "h2", "h3", "h4", "h5", "h6", "ul", "ol", "li", "blockquote"}
                    )
                    return bleach.clean(html_out, tags=allowed, strip=True)
                except Exception:
                    return html_out
            return html_out
        except Exception:
            s = html.escape(md_text, quote=False).replace("**", "<b>").replace("`", "<code>")
            return s.replace("\n", "<br>")


    def highlight_after_rendered(html_text: str, q: str) -> str:
        if not q:
            return html_text
        # highlight matched query segments
        return re.sub(re.escape(q), lambda m: f"<mark>{html.escape(m.group(0))}</mark>",
                      html_text, flags=re.IGNORECASE)


    _force = bool(st.session_state.get("force_scroll_bottom", False))
    target_id = st.session_state.get("scroll_to_msg_id", "")
    st.session_state["force_scroll_bottom"] = False
    st.session_state["scroll_to_msg_id"] = ""
    render_chat_box(st.session_state[chat_key], q, force=_force, target_id=target_id)

    # === è§’è‰²é€‰æ‹© ===
    role_help = {
        "Concept Learning": "Guide conceptual understanding.",
        "Model Iteration": "Assist with simulation and iteration.",
        "Strategy Review": "Review and improve strategies."
    }
    # --- Concise Mode toggle (EN) ---
    concise = st.toggle(
        "âœ‚ï¸ Concise mode (Get a more concise answer)",
        value=True,
        help="Limit length and number of probing questions"
    )


    def get_prompt(role):
        # âœ… Softer guidance for concise mode
        guidance_on = "Reply more concisely and ask fewer but precise questions."
        guidance_off = "Provide complete, well-reasoned explanations when useful."

        sys = f"""{roles[role]}
    Writing style guidance: {{guidance}}
    Historical Dialogue: {{history}}"""

        return ChatPromptTemplate.from_messages([
            ("system", sys),
            ("user", "{question}")
        ])


    selected_role = st.selectbox(
        "ğŸ­ Choose AI Module",
        list(roles.keys()),
        index=0,
        key="role_select"
    )

    # âœ… ä¸å†åªæ˜¾ç¤ºæ‰€é€‰æ¨¡å—ç®€ä»‹ï¼›æ”¹ä¸ºå±•ç¤ºæ‰€æœ‰æ¨¡å—çš„ä¸€è¡Œç®€ä»‹
    st.markdown('<div class="ctl-label">Modules overview</div>', unsafe_allow_html=True)
    for r in roles:
        desc = role_descriptions.get(r) or role_help.get(r, "")
        # ä¸€è¡Œã€ç®€æ´ï¼šæ¨¡å—å + ç®€çŸ­è¯´æ˜
        st.caption(f"â€¢ **{r}** â€” {desc}")

    # ä¸‹é¢ä¿æŒåŸæœ‰çš„åˆ‡æ¢é€»è¾‘ï¼ˆåˆ‡æ¢è§’è‰²æ—¶æ»šåŠ¨åˆ°åº•éƒ¨ï¼‰
    if "prev_role" not in st.session_state:
        st.session_state["prev_role"] = selected_role
    if st.session_state["prev_role"] != selected_role:
        st.session_state["prev_role"] = selected_role
        # åˆ‡æ¢è§’è‰²æ—¶ï¼Œä»…è·³åˆ°æœ€åä¸€æ¡æ¶ˆæ¯ï¼›ä¸å¼ºåˆ¶è‡ªåŠ¨ç½®åº•ï¼Œé¿å…å¯è§è·³åŠ¨
        last_idx = len(st.session_state[chat_key]) - 1
        st.session_state["scroll_to_msg_id"] = f"msg-{last_idx}" if last_idx >= 0 else ""
        st.session_state["force_scroll_bottom"] = False

    # === è¾“å…¥æ¡† + å‘é€ & æ¸…é™¤æŒ‰é’®ï¼ˆåŒä¸€è¡Œï¼‰===
    st.markdown(
        """
        <style>
        .input-row {
            display: flex;
            align-items: center; /* âœ… å‚ç›´å±…ä¸­ */
            gap: 6px; /* âœ… è¾“å…¥æ¡†ä¸æŒ‰é’®é—´è· */
        }
        .text-input { flex: 1; } /* âœ… è‡ªé€‚åº”å¡«å…… */
        .send-btn button, .clear-btn button {
            height: 45px; /* âœ… é«˜åº¦å’Œè¾“å…¥æ¡†åŒ¹é… */
            width: 45px;  /* âœ… æ­£æ–¹å½¢æŒ‰é’® */
            border-radius: 8px;
            background-color: #4da6ff;
            color: white;
            font-size: 18px;
            border: none;
        }
        .send-btn button:hover, .clear-btn button:hover {
            background-color: #1a8cff;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # =========================
    # æ–¹æ¡ˆAï¼šåŠ¨æ€ key + epochï¼ˆå¹¶æ¸…ç†æ—§é”®ï¼‰
    # =========================
    if "question_buf" not in st.session_state:
        st.session_state["question_buf"] = ""
    if "input_epoch" not in st.session_state:
        st.session_state["input_epoch"] = 0

    # å½“å‰æ´»è·ƒçš„è¾“å…¥æ¡† key
    _active_key = f"text_area_input_{st.session_state['input_epoch']}"

    # æ¸…ç†å†å² widget stateï¼Œé˜²æ­¢é•¿æœŸè¿è¡Œå †ç§¯
    for k in list(st.session_state.keys()):
        if k.startswith("text_area_input_") and k != _active_key:
            try:
                del st.session_state[k]
            except Exception:
                pass

    st.markdown('<div class="input-row">', unsafe_allow_html=True)
    question = st.text_area(
        "ğŸ’¬",
        value=st.session_state.get("question_buf", ""),  # âœ… ä»ç„¶ä½¿ç”¨ value ä½œä¸ºåˆå§‹åŒ–/åç«¯å‚æ•°æº
        key=_active_key,  # âœ… åŠ¨æ€ keyï¼šæ¯æ¬¡é‡ç½®åˆ›å»ºæ–°ç»„ä»¶ï¼Œä½¿ value ç”Ÿæ•ˆ
        height=45,
        placeholder="Type a message...",
        label_visibility="collapsed"  # âœ… éšè— label
    )

    # å‘é€æŒ‰é’®
    submit = st.button("â†©ï¸", key="send_btn", help="Send message", use_container_width=False)

    st.markdown('</div>', unsafe_allow_html=True)


    # === æ’å…¥ä»¿çœŸæ•°æ®æŒ‰é’®ï¼ˆå›è°ƒï¼Œä¸å¼ºåˆ¶ rerunï¼‰===
    def _on_insert_sim():
        # ç›´æ¥ä» session_state è¯»å–å½“å‰å³ä¾§å‚æ•°
        m = st.session_state.get("camber_pct", 2.0) / 100
        p = st.session_state.get("p_pct", 40.0) / 100
        t = st.session_state.get("thickness_pct", 12.0) / 100
        alpha = st.session_state.get("alpha_deg", 5.0)
        rho = st.session_state.get("rho", 1.225)
        V = st.session_state.get("V", 10.0)
        chord = st.session_state.get("chord", 1.0)
        mu = st.session_state.get("mu", 1.8e-5)
        M = st.session_state.get("Mach", 0.0)
        Ncrit = st.session_state.get("Ncrit", 7.0)
        a_min, a_max = st.session_state.get("alpha_range", (0.0, 10.0))
        a_step = st.session_state.get("alpha_step", 1.0)

        naca_code = naca_code_from_mpt(m, p, t)
        Re = estimate_Re(rho, V, chord, mu)

        sim_text = (
            f"My current simulation results:\n"
            f"- NACA code: {naca_code}\n"
            f"- Re â‰ˆ {Re:.0f}, Mach={M}, Ncrit={Ncrit}\n"
            f"- Î± range: {a_min}Â° to {a_max}Â°, step={a_step}Â°\n"
            f"- Current Î±={alpha}Â°\n"
            f"- Parameters: camber={m:.2f}, thickness={t:.2f}, max_camber_pos={p:.2f}\n"
            f"- Fluid: Ï={rho}, V={V}, chord={chord}, Î¼={mu}\n"
            f"â¡ï¸ How can I improve my design strategy based on this?"
        )

        # åªæ›´æ–°çŠ¶æ€å³å¯ï¼›æŒ‰é’®è¢«ç‚¹å‡»æœ¬èº«å°±ä¼šè§¦å‘ä¸€æ¬¡ rerun
        st.session_state["question_buf"] = sim_text
        st.session_state["input_epoch"] += 1
        st.session_state["force_scroll_bottom"] = True  # èŠå¤©æ¡†ç½®åº•


    # ç”¨ on_click ç»‘å®šå›è°ƒï¼›ä¸è¦å†å†™ if insert_sim: åˆ†æ”¯ï¼Œä¹Ÿä¸è¦ st.rerun()
    st.button("ğŸ“¥ Insert Simulation Data", use_container_width=True, on_click=_on_insert_sim)

    # === å‘é€æ¶ˆæ¯é€»è¾‘ ===
    if submit and question.strip():
        student_question = question.strip()  # å½“å‰è¾“å…¥æ¡†çœŸå®å†…å®¹

        # 1) å‰ç«¯å…ˆæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state[chat_key].append({"role": "user", "content": student_question})

        # 2) å…ˆè½ç›˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆå³ä¾¿è¿˜æ²¡æœ‰ AI å›å¤ï¼‰
        try:
            requests.post(
                f"{BACKEND_URL}/save_conversation/",
                json={
                    "user_id": user_id,
                    "role": selected_role,
                    "student_question": student_question,
                    "ai_response": "",  # ç©ºä¹Ÿå†™å…¥
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                timeout=10
            )
        except Exception as e:
            st.warning(f" Failed to save user message: {str(e)}")

        # 3) è°ƒç”¨ LLMï¼ˆLangGraphï¼‰
        # 3) æµå¼è°ƒç”¨ LLMï¼ˆSSEï¼‰å¹¶æŠŠæ°”æ³¡ç”»åœ¨ iframe é‡Œ
        answer = ""
        try:
            # âœ… Softer concise-mode guidance (no hard caps)
            guidance_on  = "Reply more concisely and ask fewer but precise questions."
            guidance_off = "Provide complete, well-reasoned explanations when useful."
            guidance = guidance_on if concise else guidance_off

            history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state[chat_key]])
            system_msg = f"{roles[selected_role]}\nWriting style guidance: {guidance}\nHistorical Dialogue: {history}"
            messages_oa = [
                {"role": "system", "content": system_msg},
                {"role": "user", "content": student_question}
            ]

            # --- åœ¨ä¼šè¯é‡Œè¿½åŠ â€œä¸´æ—¶æµå¼æ¶ˆæ¯â€ ---
            st.session_state[chat_key].append({
                "role": "ai_stream",  # ä¸´æ—¶ç±»å‹ï¼šæ¸²æŸ“æ—¶ä¸ ai ç›¸åŒ
                "content": "",
                "module": selected_role
            })
            stream_idx = len(st.session_state[chat_key]) - 1

            # å…ˆé‡ç»˜ä¸€æ¬¡ï¼Œå‡ºç°ç©ºå£³æ°”æ³¡
            render_chat_box(st.session_state[chat_key], q, force=True, target_id=f"msg-{stream_idx}")

            # â€”â€” æµå¼å¢é‡ï¼ˆé¦–å¸§ force=Trueï¼›ä¸­é—´å¸§èŠ‚æµï¼›æœ«å¸§ force=Trueï¼‰ â€”â€” #
            acc = ""
            last_draw = 0.0
            REDRAW_INTERVAL = 0.30  # 300msï¼Œè‚‰çœ¼æµç•…åˆä¸è‡³äºé¢‘ç¹é‡å»º
            try:
                # å…ˆç”»å‡ºç©ºå£³æµå¼æ°”æ³¡ï¼Œå¹¶å¼ºåˆ¶ç½®åº•ä¸€æ¬¡ï¼ˆé¦–å¸§ï¼‰
                render_chat_box(st.session_state[chat_key], q, force=True,
                                target_id=f"msg-{stream_idx}", stream=True)

                for delta in stream_chat_completions(messages_oa, model="gpt-4o", temperature=0.2, timeout=90):
                    if not delta:
                        continue
                    acc += delta
                    st.session_state[chat_key][stream_idx]["content"] = acc

                    now = time.time()
                    # èŠ‚æµï¼šçº¦ 80ms é‡ç»˜ä¸€æ¬¡ï¼›ä¸­é—´å¸§ä¸è¦ force
                    if now - last_draw >= REDRAW_INTERVAL:
                        render_chat_box(st.session_state[chat_key], q, force=False,
                                        target_id=f"msg-{stream_idx}", stream=True)
                        last_draw = now

                # æµå¼ç»“æŸï¼šåšä¸€æ¬¡æœ€ç»ˆé‡ç»˜ï¼ˆæ¢å¤å®‰å…¨æ¸…æ´—ä¸é«˜äº®ï¼‰ï¼Œå¹¶å¼ºåˆ¶ç½®åº•
                st.session_state[chat_key][stream_idx]["content"] = acc
                answer = (acc or "").strip()
                st.session_state[chat_key][stream_idx]["role"] = "ai"  # è½¬æ­£
                render_chat_box(st.session_state[chat_key], q, force=True,
                                target_id=f"msg-{stream_idx}", stream=False)

            except Exception:
                # æµå¼å¤±è´¥å°±å›é€€åˆ°ä¸€æ¬¡æ€§
                state = {"role": selected_role, "history": history, "question": student_question}
                answer = call_llm_with_retries(state, retries=3, base_delay=2.0)
                st.session_state[chat_key][stream_idx]["content"] = answer
                st.session_state[chat_key][stream_idx]["role"] = "ai"
                # ä¸€æ¬¡æ€§ç»“æœï¼šå®‰å…¨æ¸…æ´—+é«˜äº®ï¼Œå¼ºåˆ¶ç½®åº•
                render_chat_box(st.session_state[chat_key], q, force=True,
                                target_id=f"msg-{stream_idx}", stream=False)


        except Exception as e:
            st.error(f"LLM call failed: {e}")
            try:
                requests.post(
                    f"{BACKEND_URL}/save_conversation/",
                    json={
                        "user_id": user_id, "role": selected_role,
                        "student_question": student_question, "ai_response": f"[ERROR] {e}",
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    },
                    timeout=10
                )
            except Exception:
                pass

        # æ— æœ‰æ•ˆæ–‡æœ¬çš„æç¤º
        if not answer:
            st.info(
                "The AI returned no valid content after several attempts. Please retry in a moment or simplify your question.")

        # 5) âœ… åç«¯è½ç›˜
        if answer:
            try:
                requests.post(
                    f"{BACKEND_URL}/save_conversation/",
                    json={
                        "user_id": user_id, "role": selected_role,
                        "student_question": student_question, "ai_response": answer,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    },
                    timeout=10
                )
            except Exception as e:
                st.warning(f" Failed to save AI reply: {e}")

        # 6) æ¸…ç©ºè¾“å…¥ + å¼ºåˆ¶æ»šåº• + æœ€ç»ˆé‡ç»˜ä¸€æ¬¡ï¼ˆä¿è¯å‘½ä¸­è®¡æ•°/è¿‡æ»¤çŠ¶æ€æ­£ç¡®ï¼‰
        st.session_state["question_buf"] = ""
        st.session_state["input_epoch"] += 1
        st.session_state["force_scroll_bottom"] = True
        render_chat_box(st.session_state[chat_key], q, force=True,
                        target_id=f"msg-{len(st.session_state[chat_key]) - 1}")

# ===== Right: Tabs (Merged Geometry + Performance) =====
with col_main:
    tab_gp, tab_hist, tab_help, tab_admin = st.tabs([
        "ğŸ§© Geometry + Performance", "ğŸ—‚ï¸ History", "â“ Help", "ğŸ”‘ Admin"
    ])

    # === Geometry + Performance (one place) ===
    with tab_gp:
        # ---- Î± ä¸€è‡´ç®¡ç† ----
        if "pending_alpha_deg" in st.session_state:
            try:
                st.session_state["alpha_deg"] = float(st.session_state.pop("pending_alpha_deg"))
            except Exception:
                st.session_state.pop("pending_alpha_deg", None)
        if "alpha_deg" not in st.session_state:
            st.session_state["alpha_deg"] = 5.0

        # â€”â€” è¯»å–å…±äº«å‚æ•° â€”â€” #
        m = st.session_state.get("camber_pct", 2.0) / 100
        p = st.session_state.get("p_pct", 40.0) / 100
        t = st.session_state.get("thickness_pct", 12.0) / 100
        max_t_pos = st.session_state.get("tpos_pct", 30.0) / 100
        alpha = st.session_state.get("alpha_deg", 5.0)
        rho = st.session_state.get("rho", 1.225)
        V = st.session_state.get("V", 10.0)
        chord = st.session_state.get("chord", 1.0)
        mu = st.session_state.get("mu", 1.8e-5)
        M = st.session_state.get("Mach", 0.0)
        Ncrit = st.session_state.get("Ncrit", 7.0)
        a_min, a_max = st.session_state.get("alpha_range", (0.0, 10.0))
        a_step = st.session_state.get("alpha_step", 1.0)
        naca_code = naca_code_from_mpt(m, p, t)
        Re = estimate_Re(rho, V, chord, mu)

        # å…ˆç®— polarï¼Œé¡¶éƒ¨è¦ç”¨
        df_polar = run_xfoil_polar(naca_code, Re, M, Ncrit,
                                   float(a_min), float(a_max), float(a_step))
        if df_polar.empty:
            st.error("XFOIL produced no valid polar. Adjust Î± range/step, Re magnitude, or Ncrit.")
            df_polar = fallback_fake_polar(float(a_min), float(a_max), float(a_step))

        # æŒ‡æ ‡
        idx_current = int(np.argmin(np.abs(df_polar["alpha"].values - alpha)))
        CL = float(df_polar.loc[idx_current, "CL"])
        CD = float(df_polar.loc[idx_current, "CD"])
        LD = CL / CD if CD > 1e-12 else np.nan
        df_valid = df_polar[df_polar["CD"] > 1e-12].copy()
        df_valid["L/D"] = df_valid["CL"] / df_valid["CD"]
        idx_opt = int(df_valid["L/D"].idxmax())
        alpha_opt = float(df_valid.loc[idx_opt, "alpha"])
        ld_max = float(df_valid.loc[idx_opt, "L/D"])

        # =========================
        # é¡¶éƒ¨ï¼ˆâ‰ˆ 1/3ï¼‰ï¼šPerformanceï¼ˆKPI + å‹ç¼©å›¾ï¼‰
        # =========================
        st.subheader("Performance & Polars")

        # KPI â€”â€” å››é¡¹å›ºå®šä¸€è¡Œï¼ˆæ›´å°å­—å·ï¼‰
        st.markdown("""
        <style>
          .kpi-grid{display:grid;grid-template-columns:repeat(4,1fr);gap:10px;
                    border:1px solid #ededed;padding:6px 10px;border-radius:12px;background:#fafafa}
          .kpi .lbl{font-size:.74rem;color:#555;margin:0 0 2px 0;line-height:1.05}
          .kpi .val{font-size:1.12rem;font-weight:700;letter-spacing:.2px;margin:0;line-height:1.05;white-space:nowrap}
        </style>
        """, unsafe_allow_html=True)
        st.markdown(
            f"""
            <div class="kpi-grid">
              <div class="kpi"><div class="lbl">CL</div><div class="val">{CL:.3f}</div></div>
              <div class="kpi"><div class="lbl">CD</div><div class="val">{CD:.4f}</div></div>
              <div class="kpi"><div class="lbl">L/D</div><div class="val">{(LD if np.isfinite(LD) else float('nan')):.1f}</div></div>
              <div class="kpi"><div class="lbl">Î±* (best)</div><div class="val">{alpha_opt:.1f}Â°</div></div>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.caption(f"**Summary:** NACA {naca_code} Â· Re={Re:,.0f} Â· L/D_max={ld_max:.1f}")

        # å‹ç¼©ç‰ˆå›¾è¡¨ï¼ˆæ§åˆ¶é«˜åº¦ä»¥è´´åˆâ€œä¸Š 1/3â€ï¼‰
        tab1, tab2, tab3 = st.tabs(["CL vs Î±", "CD vs Î±", "L/D vs Î±"])


        def _pretty_axes(ax, title, xlabel, ylabel):
            ax.set_title(title)
            ax.set_xlabel(xlabel)
            ax.set_ylabel(ylabel)
            ax.grid(True, which="both", alpha=0.25, linestyle="--", linewidth=0.9)
            ax.tick_params(axis="both", labelsize=11, width=1.0)
            for sp in ax.spines.values():
                sp.set_linewidth(1.0)


        def _vline(ax, a_cur, lw=2.0):
            ax.axvline(a_cur, linestyle="--", linewidth=lw, color="#666")


        import matplotlib as mpl

        rc_small = {
            "figure.dpi": 170,
            "axes.titlesize": 13,  # å°æ ‡é¢˜
            "axes.labelsize": 12,
            "xtick.labelsize": 11,
            "ytick.labelsize": 11,
            "lines.linewidth": 2.6
        }
        with mpl.rc_context(rc_small):
            with tab1:
                fig1, ax1 = plt.subplots(figsize=(11.2, 3.8))  # è¾ƒä½é«˜åº¦
                ax1.plot(df_polar["alpha"], df_polar["CL"])
                _vline(ax1, alpha)
                _pretty_axes(ax1, "CL vs Î±", "Î± (deg)", "CL")
                fig1.tight_layout();
                st.pyplot(fig1, use_container_width=True)

            with tab2:
                fig2, ax2 = plt.subplots(figsize=(11.2, 3.8))
                ax2.plot(df_polar["alpha"], df_polar["CD"])
                _vline(ax2, alpha)
                _pretty_axes(ax2, "CD vs Î±", "Î± (deg)", "CD")
                fig2.tight_layout();
                st.pyplot(fig2, use_container_width=True)

            with tab3:
                fig3, ax3 = plt.subplots(figsize=(11.2, 3.8))
                ax3.plot(df_valid["alpha"], df_valid["L/D"])
                _vline(ax3, alpha);
                _vline(ax3, alpha_opt)
                _pretty_axes(ax3, "L/D vs Î± (with Î±* marker)", "Î± (deg)", "L/D")
                fig3.tight_layout();
                st.pyplot(fig3, use_container_width=True)

        # ä¿å­˜æŒ‰é’®ï¼ˆä¿æŒåŠŸèƒ½ï¼‰
        if st.button("ğŸ’¾ Save this result", use_container_width=True):
            try:
                payload = {
                    "user_id": user_id, "naca_code": naca_code, "camber": m, "thickness": t,
                    "max_camber_pos": p, "alpha": alpha, "rho": rho, "velocity": V, "chord": chord,
                    "mu": mu, "re": Re, "ncrit": Ncrit, "mach": M, "cl": CL, "cd": CD,
                    "ld": LD if np.isfinite(LD) else 0.0, "alpha_opt": alpha_opt, "ld_max": ld_max,
                }
                r = requests.post(f"{BACKEND_URL}/save_airfoil/", json=payload, timeout=10)
                st.success("âœ… Airfoil data saved to backend" if r.status_code == 200 else f" Save failed: {r.text}")
            except Exception as e:
                st.error(f" Error when saving: {e}")

        st.divider()

        # =========================
        # =========================
        # ä¸‹éƒ¨ï¼ˆâ‰ˆ 2/3ï¼‰ï¼šå…ˆ Airfoil é¢„è§ˆï¼ˆæ•´è¡Œï¼‰ï¼Œå†å‚æ•°ç½‘æ ¼ï¼ˆ4ä¸ªä¸€è¡Œï¼‰
        # =========================
        st.markdown("### Airfoil Preview")
        xs, ys = gen_naca4(m, p, t)

        fig, ax = plt.subplots(figsize=(12.8, 6.4))  # é¢„è§ˆæ”¾å¤§
        ax.plot(xs, ys, linewidth=2.4)
        try:
            if 0.0 <= float(p) <= 1.0:
                ax.axvline(x=float(p), linestyle="--", linewidth=1.3, label="Max camber pos")
            if 0.0 <= float(max_t_pos) <= 1.0:
                ax.axvline(x=float(max_t_pos), linestyle=":", linewidth=1.3, label="Max thickness pos")
            ax.legend(loc="upper right", frameon=False, fontsize=9, borderaxespad=0.2, handlelength=2.0)
        except Exception:
            pass
        ax.set_aspect("equal", "box")
        ax.set_xlabel("x/c", labelpad=2, fontsize=12)
        ax.set_ylabel("y/c", labelpad=2, fontsize=12)
        ax.set_title(f"NACA {naca_code}", pad=2, fontsize=12)  # æ ‡é¢˜æ›´å°
        mask = np.isfinite(xs) & np.isfinite(ys)
        if np.count_nonzero(mask) >= 2:
            xlo = float(np.nanmin(xs[mask]));
            xhi = float(np.nanmax(xs[mask]))
            ylo = float(np.nanmin(ys[mask]));
            yhi = float(np.nanmax(ys[mask]))
            xr = max(xhi - xlo, 1e-6);
            yr = max(yhi - ylo, 1e-6)
            ax.set_xlim(xlo - 0.01 * xr, xhi + 0.01 * xr)
            ax.set_ylim(ylo - 0.06 * yr, yhi + 0.06 * yr)
        else:
            ax.set_xlim(-0.01, 1.01);
            ax.set_ylim(-0.2, 0.2)
        ax.spines["top"].set_visible(False);
        ax.spines["right"].set_visible(False)
        ax.set_position([0.06, 0.12, 0.92, 0.82])  # ç”»å¾—æ›´æ»¡
        st.pyplot(fig, use_container_width=True)
        st.caption(f"Re â‰ˆ {Re:,.0f} Â· Î±={alpha:.1f}Â° Â· Ncrit={Ncrit:g} Â· M={M:g}")

        st.markdown("---")

        # ===== å‚æ•°ï¼šå››ä¸ªä¸€è¡Œï¼ˆå°½å¯èƒ½ç´§å‡‘ï¼‰=====
        st.markdown("""
        <style>
          /* ç´§å‡‘æ ‡ç­¾ä¸è¡Œè· */
          div[data-testid="stSlider"]>div>label,
          div[data-testid="stNumberInput"]>label { white-space: nowrap; font-weight: 600; }
          div[data-testid="stSlider"], div[data-testid="stNumberInput"] { margin-bottom: .42rem; }
        </style>
        """, unsafe_allow_html=True)
        st.markdown("### Parameters")

        # ç¬¬1è¡Œï¼šå‡ ä½•
        r1c1, r1c2, r1c3, r1c4 = st.columns(4, gap="small")
        with r1c1:
            st.slider("Camber (%)", 0.0, 10.0, st.session_state.get("camber_pct", 2.0), 0.1, key="camber_pct")
        with r1c2:
            st.slider("Max camber pos (%)", 0.0, 100.0, st.session_state.get("p_pct", 40.0), 1.0, key="p_pct")
        with r1c3:
            st.slider("Thickness (%)", 5.0, 20.0, st.session_state.get("thickness_pct", 12.0), 0.1, key="thickness_pct")
        with r1c4:
            st.slider("Max thickness pos (%)", 0.0, 100.0, st.session_state.get("tpos_pct", 30.0), 1.0, key="tpos_pct")

        # ç¬¬2è¡Œï¼šæµä½“
        r2c1, r2c2, r2c3, r2c4 = st.columns(4, gap="small")
        with r2c1:
            st.number_input("Ï (kg/mÂ³)", value=float(st.session_state.get("rho", 1.225)), key="rho")
        with r2c2:
            st.number_input("V (m/s)", value=float(st.session_state.get("V", 10.0)), key="V")
        with r2c3:
            st.number_input("Chord c (m)", value=float(st.session_state.get("chord", 1.0)),
                            min_value=0.05, step=0.05, key="chord")
        with r2c4:
            st.number_input("Î¼ (PaÂ·s)", value=float(st.session_state.get("mu", 1.8e-5)),
                            format="%.6e", key="mu")

        # ç¬¬3è¡Œï¼šæ±‚è§£ä¸æ‰«æï¼ˆæŠŠèŒƒå›´æ»‘å—ä¹Ÿæ”¾è¿›ä¸€åˆ—ï¼‰
        r3c1, r3c2, r3c3, r3c4 = st.columns(4, gap="small")
        with r3c1:
            st.number_input("Mach", value=float(st.session_state.get("Mach", 0.0)),
                            min_value=0.0, max_value=0.3, step=0.01, key="Mach")
        with r3c2:
            st.number_input("Ncrit", value=float(st.session_state.get("Ncrit", 7.0)),
                            min_value=1.0, max_value=12.0, step=0.5, key="Ncrit")
        with r3c3:
            st.slider("Scan range Î± (Â°)", 0.0, 15.0,
                      st.session_state.get("alpha_range", (0.0, 10.0)), 0.5, key="alpha_range")
        with r3c4:
            st.number_input("Î”Î± (Â°)", value=float(st.session_state.get("alpha_step", 1.0)),
                            min_value=0.1, max_value=2.0, step=0.1, key="alpha_step")

        # ç¬¬4è¡Œï¼šå½“å‰æ”»è§’ï¼ˆè¡¥æ»¡4åˆ—ä»¥ä¿æŒæ•´é½ï¼‰
        r4c1, r4c2, r4c3, r4c4 = st.columns(4, gap="small")
        with r4c1:
            _alpha_kwargs = dict(min_value=0.0, max_value=15.0, step=0.5, key="alpha_deg")
            if "alpha_deg" not in st.session_state:
                _alpha_kwargs["value"] = 5.0
            st.slider("Current Î± (Â°)", **_alpha_kwargs)
        with r4c2:
            st.empty()
        with r4c3:
            st.empty()
        with r4c4:
            st.empty()

    # === History Tab ===
    with tab_hist:
        st.subheader("ğŸ“œ My History")

        # åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ Refresh History", use_container_width=True):
            st.session_state["refresh_history"] = True

        # é»˜è®¤ç¬¬ä¸€æ¬¡è¿›å…¥å°±åˆ·æ–°
        if "refresh_history" not in st.session_state:
            st.session_state["refresh_history"] = True

        df_hist = None
        if st.session_state["refresh_history"]:
            try:
                resp = requests.get(f"{BACKEND_URL}/export_airfoils/{user_id}", timeout=10).json()
                if resp:
                    df_hist = pd.DataFrame(resp)
                    st.dataframe(
                        df_hist[[
                            "id", "user_id", "naca_code", "camber", "thickness",
                            "max_camber_pos", "alpha", "rho", "velocity", "chord",
                            "mu", "re", "ncrit", "mach", "cl", "cd", "ld",
                            "alpha_opt", "ld_max", "timestamp"
                        ]],
                        use_container_width=True, height=400
                    )
                else:
                    st.info("No saved records yet.")
            except Exception as e:
                st.warning(f" Backend fetch failed: {e}")

            # è‡ªåŠ¨åˆ·æ–°å®Œæˆåå…³é—­æ ‡å¿—ï¼Œä¸‹æ¬¡åªæœ‰ç‚¹åˆ·æ–°æŒ‰é’®æ‰ä¼šå†è¯·æ±‚
            st.session_state["refresh_history"] = False

        # âœ… å¦‚æœæœ‰æ•°æ®ï¼Œæä¾›å¯¼å‡ºæŒ‰é’®ï¼ˆå³ä¾¿æ²¡åˆ·æ–°è¿‡ä¹Ÿèƒ½ç”¨ï¼‰
        if df_hist is not None and not df_hist.empty:
            csv = df_hist.to_csv(index=False).encode("utf-8")
            st.download_button(
                label="ğŸ“¥ Download My History (CSV)",
                data=csv,
                file_name=f"{user_id}_history.csv",
                mime="text/csv",
                use_container_width=True
            )
        # === Help Tab ===
        with tab_help:
            st.markdown("## Help Center")
            st.caption("AI-Enhanced Airfoil Design & Learning Lab â€” Updated quick guide for the current interface")

            st.markdown("### What this app does")
            st.markdown("""
        This web app combines **NACA geometry preview**, **XFOIL polar analysis** (CL/CD/CM & L/D),
        and **role-based AI tutoring** for concept learning, model iteration, and strategy review.
        The interface is organized into a **left Dialogue column** and a **right multi-tab workspace**.
            """)

            st.markdown("### Page layout at a glance")
            st.markdown("""
        - **Left column â€” Dialogue**
          - **ğŸ­ Choose AI Module** (Concept Learning / Model Iteration / Strategy Review)
          - **Filter modules**, **Search** with **Prev / Next / â¬‡ï¸ Latest**
          - **ğŸ“œ Restore historical dialogue** (loads your past chat by user)
          - **Input & Send**; **ğŸ“¥ Insert Simulation Data** auto-pastes current parameters
        - **Right column â€” Tabs**
          - **ğŸ§© Geometry + Performance** (merged): KPIs & polar plots (top), large airfoil preview, then a **4-per-row** parameter grid
          - **ğŸ—‚ï¸ History**: fetch, view, and download your saved runs (per user)
          - **â“ Help**: this guide
          - **ğŸ”‘ Admin**: export all conversations/airfoils (requires admin password)
            """)

            st.markdown("### Quick start")
            st.markdown("""
        1. Go to **ğŸ§© Geometry + Performance** and set parameters:
           - Geometry: camber **m%**, max-camber position **p%**, thickness **t%**, (optional) max-thickness position.
           - Flow: **Ï, V, chord c, Î¼**; the app computes **Re = ÏVc/Î¼**.
           - Solver: **Mach**, **Ncrit** (typ. 5â€“9).
           - Scan: **Î± range** and **Î”Î±** for ASEQ.
        2. The top area shows **KPIs** (CL, CD, L/D, best Î±\*) and three compact plots:
           **CL vs Î±**, **CD vs Î±**, **L/D vs Î±** with markers at current **Î±** and **Î±\***.
        3. Scroll down to **Airfoil Preview** for a large NACA outline (equal-axis plot).
        4. Use the **Parameters** grid (4 controls per row) to iterate quickly.
        5. On the left, pick a role in **ğŸ­ Choose AI Module**.  
           Ask a question or click **ğŸ“¥ Insert Simulation Data** to paste the current setup and request feedback.
        6. Save a run with **ğŸ’¾ Save this result** and review it later in **ğŸ—‚ï¸ History** (you can download CSV).
            """)

            with st.expander("AI roles â€” when to use which"):
                st.markdown("""
        - **Concept Learning** â€” Clarifies core concepts (lift, stall, Reynolds number, etc.) with guiding questions.  
        - **Model Iteration** â€” Designs reproducible parameter scans, compares outcomes, and suggests next tweaks.  
        - **Strategy Review** â€” Critiques your claimâ€“evidenceâ€“warrant chain and proposes actionable next steps.
                """)

            with st.expander("Reading the Performance section"):
                st.markdown("""
        - **KPIs**: CL, CD, **L/D**, and **Î±\*** (the peak **L/D** in the scanned Î± range).  
        - **Plots**: three tabs (**CL vs Î±**, **CD vs Î±**, **L/D vs Î±**). Vertical lines mark the **current Î±** and **Î±\***.  
        - If XFOIL fails to return valid polars, the app shows a **fallback simulated curve** so the UI remains usableâ€”adjust inputs and recompute.
                """)

            with st.expander("Parameter tips"):
                st.markdown("""
        - Start with moderate geometry (e.g., **m** 2â€“3%, **t** 12%) and scan **Î± = 0Â°â€“10Â°**, **Î”Î± = 0.5Â°â€“1Â°**.  
        - Keep **Mach â‰¤ 0.3** for incompressible assumptions.  
        - Try **Ncrit â‰ˆ 7** first; move Â±2 if convergence is poor.  
        - Extreme shapes or very small **Re** can cause non-physical results or empty polars.
                """)

            with st.expander("Dialogue good practices"):
                st.markdown("""
        - Use **ğŸ“¥ Insert Simulation Data** before asking for design adviceâ€”this gives the AI full context.  
        - Prefer â€œreasoningâ€ prompts, e.g., *â€œIf I increase **t%** at fixed **Re**, what happens to stall and **L/D**?â€*  
        - For argumentation, structure notes as **Claim â†’ Evidence â†’ Warrant**; add **Qualifiers/Rebuttals** when needed.  
        - Toggle **âœ‚ï¸ Concise mode** if you want shorter, more to-the-point answers.  
          > Internal guidance when enabled: â€œReply more concisely and ask fewer but precise questions.â€
                """)

            st.markdown("### Troubleshooting")
            st.markdown("""
        - **No polar or empty `polar.out`** â†’ Check Î± range/Î”Î±, **Re** magnitude, and **Ncrit**; ensure `xfoil.exe` exists in the app root (Windows).  
        - **L/D = NaN or odd** â†’ Often due to **CD â‰ˆ 0** or sparse samples; reduce **Î”Î±** and/or widen Î± range.  
        - **Port already in use (8000/8501)** â†’ Stop the process using that port (Windows: Task Manager or `netstat` + `taskkill`).  
        - **Input not clearing** â†’ The app rotates the input widget key after submission; refresh if local state drifts.
            """)

            st.markdown("### Data & ethics")
            st.markdown("""
        Use this app for learning and research. If you publish or submit coursework, cite your methods and parameters.
        Dialogue logs and run data may be stored for research; anonymize as required by your local IRB/ethics policy.
            """)

    # === Admin Panel ===
    with tab_admin:
        if is_admin:
            st.success("âœ… Logged in as Admin")
            st.markdown("### Export All Data")

            # Conversations
            if st.button("ğŸ“¥ Download All Conversations (CSV)", use_container_width=True):
                try:
                    resp = requests.get(f"{BACKEND_URL}/admin/export_all_conversations", timeout=20)
                    if resp.status_code == 200:
                        csv = resp.content
                        st.download_button(
                            label="â¬‡ï¸ Save Conversations",
                            data=csv,
                            file_name="all_conversations.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    else:
                        st.error(f" Failed: {resp.text}")
                except Exception as e:
                    st.error(f" Error fetching conversations: {e}")

            # Airfoils
            if st.button("ğŸ“¥ Download All Airfoils (CSV)", use_container_width=True):
                try:
                    resp = requests.get(f"{BACKEND_URL}/admin/export_all_airfoils", timeout=20)
                    if resp.status_code == 200:
                        csv = resp.content
                        st.download_button(
                            label="â¬‡ï¸ Click here to save Airfoils",
                            data=csv,
                            file_name="all_airfoils.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    else:
                        st.error(f" Failed: {resp.text}")
                except Exception as e:
                    st.error(f" Error fetching airfoils: {e}")
        else:
            st.warning("Enter the correct admin password to access this panel.")

