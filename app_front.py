# -*- coding: utf-8 -*-
# File: app.py
# Description: Multi-user Airfoil Design Assistant (Windows + Admin Panel)

import streamlit as st
import streamlit.components.v1 as components
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable
from langchain.memory import ConversationBufferMemory

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import shutil, subprocess, tempfile, os, requests
import re, html
import json






# ===== Config =====
BACKEND_URL = os.getenv("BACKEND_URL", "http://139.196.12.84:8000")
ADMIN_PASS = os.getenv("ADMIN_PASS", "ecnustju")

import os
os.environ["OPENAI_API_KEY"] = "sk-ä½ çš„key"

# =========================
# â€”â€” XFOIL Wrapper (Windows) â€”â€”
# =========================
try:
    from xfoil import XFoil
    from xfoil.model import Airfoil
    XFOIL_PY_OK = True
except Exception:
    XFOIL_PY_OK = False


# =========================
# â€”â€” XFOIL Wrapper (Windows ä¸“ç”¨) â€”â€”
# =========================

def _which_xfoil():
    """åªåœ¨å½“å‰ç›®å½•ä¸‹æŸ¥æ‰¾ xfoil.exe"""
    exe_path = os.path.join(os.getcwd(), "xfoil.exe")
    if os.path.exists(exe_path):
        return exe_path
    raise FileNotFoundError("âŒ æ²¡æœ‰æ‰¾åˆ° xfoil.exeï¼Œè¯·ç¡®è®¤å®ƒåœ¨ bot-remote-windows ç›®å½•ä¸‹")

def run_xfoil_cli_polar(naca_code: str, Re: float, Mach: float, Ncrit: float,
                        alpha_start: float, alpha_end: float, alpha_step: float) -> pd.DataFrame:
    exe = os.path.abspath("xfoil.exe")  # âœ… å¼ºåˆ¶ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ xfoil.exe
    if not os.path.exists(exe):
        print("âŒ xfoil.exe not found in", exe)
        return pd.DataFrame(columns=["alpha", "CL", "CD", "CM"])

    with tempfile.TemporaryDirectory() as td:
        pol_path = os.path.join(td, "polar.out")

        # âœ… è¾“å…¥è„šæœ¬ï¼ˆä¸¥æ ¼æŒ‰ç…§ Windows ç‰ˆ XFOIL è¦æ±‚ï¼‰
        script = f"""
NACA {naca_code}
PANE
OPER
VISC {Re:.3e}
MACH {Mach:.4f}
VPAR
N {int(Ncrit)}

PACC
{pol_path}

ASEQ {alpha_start:.1f} {alpha_end:.1f} {alpha_step:.1f}
PACC

QUIT
"""

        # âœ… åœ¨å½“å‰ç›®å½•è¿è¡Œï¼ˆé¿å… exe æ‰¾ä¸åˆ°ï¼‰
        result = subprocess.run(
            [exe],
            input=script,
            text=True,
            capture_output=True,
            cwd=os.getcwd(),
            timeout=60
        )

        # è°ƒè¯•è¾“å‡ºï¼ˆåªçœ‹å‰ 400 å­—ç¬¦ï¼‰
        print("=== XFOIL STDOUT ===\n", (result.stdout or "")[:400])
        print("=== XFOIL STDERR ===\n", (result.stderr or "")[:400])

        if not os.path.exists(pol_path):
            print("âŒ polar.out not generated")
            return pd.DataFrame(columns=["alpha", "CL", "CD", "CM"])

        # âœ… è§£æ polar.out
        rows = []
        with open(pol_path, "r") as f:
            for line in f:
                if ("alpha" in line and "CL" in line and "CD" in line) or set(line.strip()) <= set("-= "):
                    continue
                parts = line.strip().split()
                if len(parts) >= 5:
                    try:
                        a = float(parts[0])
                        cl = float(parts[1])
                        cd = float(parts[2])
                        cm = float(parts[4])
                        rows.append((a, cl, cd, cm))
                    except Exception:
                        continue

        if not rows:
            print("âš ï¸ polar.out parsed but empty")
            return pd.DataFrame(columns=["alpha", "CL", "CD", "CM"])

        return pd.DataFrame(rows, columns=["alpha", "CL", "CD", "CM"]).sort_values("alpha").reset_index(drop=True)

@st.cache_data(show_spinner=True)
def run_xfoil_polar(naca_code: str, Re: float, Mach: float, Ncrit: float,
                    alpha_start: float, alpha_end: float, alpha_step: float) -> pd.DataFrame:
    if XFOIL_PY_OK:
        try:
            af = Airfoil.NACA(naca_code)
            xf = XFoil()
            xf.airfoil = af
            xf.Re = max(Re, 1e4)
            xf.M = max(Mach, 0.0)
            xf.n_crit = Ncrit
            try:
                a, cl, cd, cm, _ = xf.aseq(alpha_start, alpha_end, alpha_step)
            except Exception:
                A = np.arange(alpha_start, alpha_end + 1e-9, alpha_step)
                alist, clist, cdlist, cmlist = [], [], [], []
                for a0 in A:
                    try:
                        cl0, cd0, cm0, _cp = xf.a(a0)
                        alist.append(a0); clist.append(cl0); cdlist.append(cd0); cmlist.append(cm0)
                    except Exception:
                        continue
                a = np.array(alist); cl = np.array(clist); cd = np.array(cdlist); cm = np.array(cmlist)
            mask = np.isfinite(a) & np.isfinite(cl) & np.isfinite(cd) & np.isfinite(cm)
            df = pd.DataFrame({"alpha": a[mask], "CL": cl[mask], "CD": cd[mask], "CM": cm[mask]})
            df = df.sort_values("alpha").reset_index(drop=True)
            if not df.empty:
                return df
        except Exception:
            pass
    return run_xfoil_cli_polar(naca_code, Re, Mach, Ncrit, alpha_start, alpha_end, alpha_step)


def fallback_fake_polar(alpha_start, alpha_end, alpha_step):
    alphas = np.arange(alpha_start, alpha_end + 1e-9, alpha_step)
    CL = 0.1 * alphas
    CD = 0.01 + 0.002 * alphas**2
    CM = -0.05 * np.ones_like(alphas)
    return pd.DataFrame({"alpha": alphas, "CL": CL, "CD": CD, "CM": CM})


# =========================
# â€”â€” LangGraph + ChatGPTï¼ˆä¿®å¤ç‰ˆï¼‰ â€”â€”
# =========================
import os
from langchain_openai import ChatOpenAI

# typing å…¼å®¹å¯¼å…¥
try:
    from typing import TypedDict, Dict, Any
except ImportError:            # < Py3.8 æ‰ä¼šèµ°åˆ°è¿™é‡Œ
    from typing_extensions import TypedDict
    from typing import Dict, Any

llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.2,
    api_key="sk-VrwOEEFLgjJwSOjH5pHRTDorgf0SmJVQrjK2D1uyjxZcfsrn",   # å†™åœ¨è¿™é‡Œ
    base_url="http://49.51.37.239:3006/v1"  # ä¸­è½¬åœ°å€
)
memory = ConversationBufferMemory(memory_key="history")

roles = {
    "Concept Learning": (
        "You are an AI tutor specialized in **conceptual learning**. "
        "Your role is to guide students in breaking down abstract fluid mechanics concepts "
        "into smaller, teachable parts. "
        "You should always respond in English with a **guiding and questioning tone**, "
        "encouraging the student to reflect. "
        "Never give the final answer directly. "
        "Ask questions such as: 'Which factors do you think are important, and why?' "
        "or 'How would changing the camber affect the lift coefficient?'"
    ),
    "Model Iteration": (
        "You are an AI assistant specialized in **model iteration and experiment design**. "
        "Your role is to help students analyze simulation data, propose adjustments, "
        "and suggest possible experiment setups. "
        "Always respond in English with a **coaching style**, focusing on reasoning and exploration, "
        "rather than giving direct solutions. "
        "Encourage the student to test ideas and compare results, for example: "
        "'What would happen if you increased the Reynolds number?' "
        "or 'How could you verify whether thickness has a stronger impact than camber?'"
    ),
    "Strategy Review": (
        "You are an AI mentor specialized in **strategy review and reflection**. "
        "Your role is to evaluate the studentâ€™s current approach and give constructive feedback "
        "on their design strategies. "
        "Always respond in English with a **critical but supportive tone**, "
        "pointing out strengths and possible improvements. "
        "Do not just state the answer â€” instead, highlight gaps and suggest next steps. "
        "For example: 'Your strategy improves L/D ratio, but it may ignore stall effects. "
        "What adjustment could account for that?'"
    )
}

role_guides = {
    "Concept Learning": [
        "Break down the key sub-concepts of 'Lift Coefficient' into a 3-level teachable structure.",
        "Based on C-K theory, propose 3 concept-to-concept expansion paths, each with an engineering context."
    ],
    "Model Iteration": [
        "Design a reproducible experiment to compare two airfoils at Re=3e5 (include variables and indicators).",
        "Provide suggestions for XFOIL polar scan parameter settings and explain the rationale for Ncrit values."
    ],
    "Strategy Review": [
        "Check the logic of this argument about lift-to-drag ratio, and point out gaps in claimâ€“evidenceâ€“warrant chain.",
        "Give 3 rewriting suggestions to make the argument more academic and evidence-complete."
    ]
}

role_descriptions = {
    "Concept Learning": "Focus on clarifying core concepts.",
    "Model Iteration": "Assist with experiments and parameter tuning.",
    "Strategy Review": "Give feedback on strategies and reasoning."
}

def get_prompt(role):
    return ChatPromptTemplate.from_messages([
        ("system", roles[role] + "\nHistorical Dialogue: {history}"),
        ("user", "{question}")
    ])

# ---- State ç±»å‹ï¼ˆdict å½¢å¼ï¼ŒLangGraph æ¨èï¼‰----
class GraphState(TypedDict, total=False):
    role: str
    history: str
    question: str
    content: str   # ç”±èŠ‚ç‚¹å†™å›

# ---- å°†æ¯ä¸ªè§’è‰²å°è£…ä¸ºè¿”å› dict çš„èŠ‚ç‚¹ ----
def create_node(role: str):
    prompt = get_prompt(role)
    chain = prompt | llm

    def _run(state: GraphState) -> Dict[str, Any]:
        res = chain.invoke({
            "history": state.get("history", ""),
            "question": state.get("question", "")
        })
        text = getattr(res, "content", str(res))
        return {"content": text}   # âœ… å†™å›åˆ°çŠ¶æ€
    return _run

graph = StateGraph(GraphState)
for r in roles:
    graph.add_node(r, create_node(r))

# ---- æ¡ä»¶è·¯ç”±ï¼šå‡½æ•°åªè¿”å›â€œä¸‹ä¸€èŠ‚ç‚¹åâ€ï¼Œä¸è¦å½“èŠ‚ç‚¹æœ¬èº«è¿”å› ----
def route_role(state: GraphState) -> str:
    return state["role"]

# ğŸš© router èŠ‚ç‚¹å¿…é¡»è¿”å› dictï¼Œè¿™é‡Œç”¨ç©ºæ“ä½œå ä½
graph.add_node("router", lambda state: {})   # âœ… ä¸è¦è¿”å›å­—ç¬¦ä¸²ï¼
graph.set_entry_point("router")
graph.add_conditional_edges("router", route_role, {r: r for r in roles})

for r in roles:
    graph.add_edge(r, END)

app = graph.compile()
# >>> PATCH: LLM retry helper (place right after `app = graph.compile()`)
import time as _t

def call_llm_with_retries(state: dict, retries: int = 3, base_delay: float = 2.0) -> str:
    """
    Call the LangGraph app with simple exponential backoff.
    Returns the LLM text or "" if all attempts failed or empty.
    """
    last_err = None
    for k in range(retries):
        try:
            resp_state = app.invoke(state)
            txt = (resp_state or {}).get("content", "")
            if isinstance(txt, str) and txt.strip():
                return txt.strip()
        except Exception as e:
            last_err = e
        # backoff: 2s, 4s, 8s ...
        _t.sleep(base_delay * (2 ** k))
    # all failed or got empty content
    if last_err:
        # è®©è°ƒç”¨æ–¹å†³å®šæ˜¯å¦å±•ç¤ºé”™è¯¯/è½ç›˜
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›ç©ºä¸²ä»¥èµ°ç»Ÿä¸€å…œåº•æç¤º
        pass
    return ""



# =========================
# â€”â€” Geometry Utils â€”â€”
# =========================
@st.cache_data(show_spinner=False)
def gen_naca4(m: float, p: float, t: float, n_pts: int = 200):
    x = np.linspace(0, 1, n_pts)
    yt = 5 * t * (
        0.2969 * np.sqrt(np.clip(x, 1e-12, 1.0))
        - 0.1260 * x - 0.3516 * x**2 + 0.2843 * x**3 - 0.1015 * x**4
    )
    p_eps = max(p, 1e-12); q_eps = max(1-p, 1e-12)
    yc = np.where(x < p,
        (m/(p_eps**2))*(2*p*x - x**2),
        (m/(q_eps**2))*((1-2*p) + 2*p*x - x**2)
    )
    dyc_dx = np.where(x < p,
        (2*m/(p_eps**2))*(p - x),
        (2*m/(q_eps**2))*(p - x)
    )
    theta = np.arctan(dyc_dx)
    xu = x - yt*np.sin(theta); yu = yc + yt*np.cos(theta)
    xl = x + yt*np.sin(theta); yl = yc - yt*np.cos(theta)
    xs = np.concatenate([xl[::-1], xu[1:]])
    ys = np.concatenate([yl[::-1], yu[1:]])
    return xs, ys


def naca_code_from_mpt(m: float, p: float, t: float) -> str:
    m_pct = int(round(m*100)); p_tenths = int(round(p*10)); t_pct = int(round(t*100))
    return f"{m_pct}{p_tenths}{t_pct:02d}"


def estimate_Re(rho: float, V: float, chord: float, mu: float) -> float:
    return (rho*V*chord)/max(mu, 1e-9)


# =====================
# â€”â€” Streamlit UI â€”â€”
# =====================
st.set_page_config(page_title="Fluid Mechanics AI Assistant", layout="wide")

# --- åˆå¹¶ä¸”åŠ å›ºçš„æ ·å¼ï¼ˆåªä¿ç•™è¿™ä¸€ä¸ª <style>ï¼‰ ---
st.markdown("""
<style>
/* 1) è®©ä¸»å®¹å™¨é¡¶éƒ¨æœ‰å……è¶³ç•™ç™½ï¼Œé¿å…è¢«å›ºå®šå¤´éƒ¨è¦†ç›– */
.block-container {
    padding-top: 2.0rem !important;   /* å»ºè®® â‰¥1.6remï¼›è‹¥ä»è¢«é®æŒ¡ï¼Œè°ƒåˆ° 2.4rem */
    padding-bottom: 0.8rem !important;
    overflow: visible !important;      /* é˜²æ­¢è¢«è£åˆ‡ */
}

/* 2) ä¿è¯æ ‡é¢˜æœ¬èº«ä¸è¢«æŒ¤ï¼›è¡Œé«˜å……è¶³ã€å¤–è¾¹è·åˆç† */
h1 {
    margin: 0 0 .6rem 0 !important;
    line-height: 1.18 !important;
    word-break: break-word;
}

/* 3) æœ‰äº›é¡¹ç›®é‡Œä¼šç»™ header/å®¹å™¨è®¾ç½® overflow:hiddenï¼Œè¿™é‡Œå¼ºåˆ¶è§£é™¤ */
header, [data-testid="stHeader"] {
    overflow: visible !important;
}

/* 4) æ¬¡çº§æ ‡é¢˜æ›´ç´§å‡‘ï¼ˆå¯é€‰ï¼‰ */
h3, h4, h5 { margin: .2rem 0 .2rem 0 !important; }

/* 5) ä¸è¦ç”¨ä¼šå˜åŠ¨çš„æƒ…ç»ªç±»åï¼Œä»¥ä¸‹ä»…å¯¹å¸¸ç”¨æ§ä»¶è½»é‡æ”¶ç´§ï¼ˆå¯é€‰ï¼‰ */
div[data-testid="stSlider"], div[data-testid="stNumberInput"] { margin-bottom: .35rem; }

/* 6) å³ä¾§è¾“å…¥è¡Œå¾®è°ƒï¼ˆå¯é€‰ï¼‰ */
.input-row { margin-top: .4rem; }

</style>
""", unsafe_allow_html=True)
st.markdown("""
<style>
/* Top-anchored, no vertical blank area for matplotlib images/canvas */
.fixed-plot {
  height: 320px;                /* ä½ ä¹Ÿå¯ä»¥æ”¹æˆ 300/340ï¼›å›ºå®šé«˜åº¦ï¼Œé¿å…è·³åŠ¨ */
  position: relative;
  overflow: hidden;
}

/* è®©å›¾ç‰‡/ç”»å¸ƒé“ºæ»¡å®¹å™¨ï¼Œé«˜åº¦ä¼˜å…ˆï¼Œä¿æŒç­‰æ¯”ï¼Œä¸å†å±…ä¸­ */
.fixed-plot img, .fixed-plot canvas {
  position: absolute;
  inset: 0;                     /* top:0 right:0 bottom:0 left:0 */
  width: 100%;
  height: 100%;
  object-fit: contain;          /* ä¿æŒç­‰æ¯” */
  object-position: top left;    /* é¡¶å¯¹é½ï¼ˆä¹Ÿå¯ç”¨ 'top center'ï¼‰*/
  display: block;               /* å»æ‰ inline å…ƒç´ é€ æˆçš„å‚ç›´å¯¹é½å½±å“ */
}
</style>
""", unsafe_allow_html=True)


st.title("AI-Enhanced Airfoil Design & Learning Lab")
st.caption("An AI-powered airfoil design assistant for NACA geometry preview, XFOIL polar analysis, and role-based learning guidance.")

# ==== Sidebar: User / Admin Login ====
st.sidebar.title("Login")
user_id = st.sidebar.text_input("Enter your User ID", value="guest")
st.sidebar.markdown("---")
st.sidebar.subheader("Admin Access")
admin_password = st.sidebar.text_input("Enter admin password", type="password")
is_admin = (admin_password == ADMIN_PASS)

# ==== Session init ====
if "param_history" not in st.session_state:
    st.session_state.param_history = []
if "prev_role" not in st.session_state:
    st.session_state.prev_role = None

# âœ… æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„èŠå¤©è®°å½•
chat_key = f"chat_history_{user_id}"
if chat_key not in st.session_state:
    st.session_state[chat_key] = []

# ==== Layout ====
col_chat, col_main = st.columns([1, 1], gap="large")

import time

# ===== Left: Dialogue =====
with col_chat:
    # ï¼ˆä¸è¦æ ‡é¢˜äº†ï¼‰
    # === æ ·å¼å®šä¹‰ ===
    st.markdown(
        """
        <style>
        .chat-wrapper {
            background-color: #f5f5f5;
            padding: 12px;
            border-radius: 10px;
            height: 55vh;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
        }
        .bubble {
            max-width: 75%;
            padding: 8px 12px;
            margin: 6px;
            border-radius: 8px;
            word-wrap: break-word;
            font-size: 14px;
            line-height: 1.4;
        }
        .user-bubble {
            background-color: #95ec69;
            margin-left: auto;
            text-align: right;
        }
        .ai-bubble {
            margin-right: auto;
            text-align: left;
        }
        .concept { background-color: #d0e6ff; }
        .model { background-color: #ffe4b3; }
        .strategy { background-color: #e6ccff; }
        .system {
            color: #555;
            text-align: center;
            font-size: 13px;
            font-style: italic;
            margin: 4px 0;
        }
        /* æŒ‰é’®ç»Ÿä¸€æ ·å¼ */
        div[data-testid="stButton"] button {
            background-color: #4da6ff;
            color: white;
            border-radius: 6px;
            padding: 0.3em 0.6em;
            font-size: 14px;
            border: none;
        }
        div[data-testid="stButton"] button:hover {
            background-color: #1a8cff;
            color: white;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )



    st.markdown(
        """
        <style>
        /* â€”â€” ç´§å‡‘ï¼šcomponents.html/æœç´¢/æŒ‰é’® â€”â€” */
        .ctl-label { font-size: 0.82rem; color:#444; margin:0 0 4px 2px; }
        div[data-testid="stMultiSelect"] > div { margin-bottom: 0.2rem; }
        div[data-baseweb="select"] { min-height: 34px; }
        div[data-baseweb="select"] > div { min-height: 34px; padding-top: 2px; padding-bottom: 2px; }
        div[data-baseweb="tag"] { margin: 2px 4px; transform: scale(0.92); }
        div[data-testid="stTextInput"] input { height: 34px; padding: 2px 8px; font-size: 0.90rem; }
        div[data-testid="stTextInput"] label { margin-bottom: 4px; font-size: 0.82rem; }
        .small-btn button { height: 34px; padding: 0 10px; font-size: 0.90rem; border-radius: 8px; }
        .compact-row { margin-bottom: 0.25rem; }
        
        </style>
        """,
        unsafe_allow_html=True,
    )

    # === æ¢å¤å†å²æŒ‰é’® ===
    if st.button("ğŸ“œ Restore historical dialogue", use_container_width=True):
        try:
            resp = requests.get(f"{BACKEND_URL}/export_conversations/{user_id}", timeout=10)
            if resp.status_code == 200:
                history_data = resp.json()
                history_data = sorted(history_data, key=lambda x: x["timestamp"])
                past_msgs = []
                if history_data:
                    past_msgs.append({"role": "system", "content": "â€”â€” ğŸ•’ Historical Dialogue â€”â€”"})
                    for h in history_data:
                        if h.get("student_question"):
                            past_msgs.append({"role": "user", "content": h["student_question"]})
                        if h.get("ai_response"):
                            past_msgs.append({
                                "role": "ai",
                                "content": h["ai_response"],
                                "module": h.get("role", "AI")
                            })
                st.session_state[chat_key] = past_msgs  # âœ… è¦†ç›–
                st.success("âœ… History has been rewritten")
                st.session_state["force_scroll_bottom"] = True  # âœ… æ¢å¤åå¼ºåˆ¶åˆ°åº•
            else:
                st.info("â„¹ï¸ No historical records were found")
        except Exception as e:
            st.error(f"âš ï¸ Error fetching history: {e}")

    # === æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„èŠå¤© key ===
    chat_key = f"chat_history_{user_id}"
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []

    # === æ»šåŠ¨ä¸æœç´¢çš„ session çŠ¶æ€ ===
    if "force_scroll_bottom" not in st.session_state:
        st.session_state["force_scroll_bottom"] = False
    if "scroll_to_msg_id" not in st.session_state:
        st.session_state["scroll_to_msg_id"] = ""
    if "chat_search_q" not in st.session_state:
        st.session_state["chat_search_q"] = ""
    if "search_hits" not in st.session_state:
        st.session_state["search_hits"] = []
    if "search_pos" not in st.session_state:
        st.session_state["search_pos"] = 0
    if "chat_filter_roles" not in st.session_state:
        st.session_state["chat_filter_roles"] = list(roles.keys())  # é»˜è®¤å…¨é€‰

    # === ç­›é€‰ + æœç´¢æ§ä»¶ï¼ˆåŒåˆ—å¸ƒå±€ï¼šå·¦ç­›é€‰ / å³æœç´¢+æŒ‰é’®ï¼‰===
    st.markdown("""
    <style>
      /* å³ä¾§æŒ‰é’®ï¼šä¿è¯æ¨ªå‘æ˜¾ç¤ºå¹¶ä¸æŠ˜è¡Œ */
      .small-btn button {
        height: 28px;          /* å‡å°æŒ‰é’®é«˜åº¦ */
        padding: 0 10px;       /* å‡å°å†…è¾¹è· */
        font-size: 0.85rem;    /* ç¨å¾®å‡å°å­—ä½“ */
        border-radius: 6px;
        white-space: nowrap;
        min-width: 80px;
      }
      .ctrl-group { 
        margin-top: 0.1rem;    /* å‡å°å‚ç›´é—´è· */
        margin-bottom: 0.1rem;
      }
      /* æ ‡ç­¾æ›´ç´§å‡‘ */
      .ctl-label { 
        font-size: 0.82rem; 
        color:#bbb; 
        margin: 0 0 3px 2px;   /* å‡å°æ ‡ç­¾åº•éƒ¨é—´è· */
      }
      /* è¾“å…¥æ¡†æ›´çŸ®ä¸€äº› */
      div[data-testid="stTextInput"] input { 
        height: 32px;          /* å‡å°æœç´¢æ¡†é«˜åº¦ */
        padding: 3px 8px; 
        font-size: 0.9rem; 
      }
      div[data-testid="stMultiSelect"] > div { margin-bottom: 0.2rem; }
      div[data-baseweb="select"] { min-height: 32px; }  /* åŒ¹é…æœç´¢æ¡†é«˜åº¦ */
      div[data-baseweb="select"] > div { 
        min-height: 32px; 
        padding-top: 1px; 
        padding-bottom: 1px; 
      }
      div[data-baseweb="tag"] { 
        margin: 1px 3px; 
        transform: scale(0.9); /* ç¨å¾®ç¼©å°æ ‡ç­¾ */
      }
    </style>
    """, unsafe_allow_html=True)

    ctl_left, ctl_right = st.columns([1, 1], gap="small")

    # å·¦ä¾§ï¼šæ¨¡å—ç­›é€‰ï¼ˆä¿æŒä¸å˜ï¼‰
    with ctl_left:
        st.markdown('<div class="ctl-label">Filter modules</div>', unsafe_allow_html=True)
        st.session_state["chat_filter_roles"] = st.multiselect(
            label="Filter modules",
            options=list(roles.keys()),
            default=st.session_state["chat_filter_roles"],
            help="ç­›é€‰æ˜¾ç¤ºä¸åŒ AI æ¨¡å—çš„æ¶ˆæ¯ï¼ˆç”¨æˆ·æ¶ˆæ¯å§‹ç»ˆæ˜¾ç¤ºï¼‰",
            label_visibility="collapsed"
        )

    # å³ä¾§ï¼šæœç´¢ + æŒ‰é’®ï¼ˆä¼˜åŒ–å¸ƒå±€ï¼‰
    with ctl_right:
        st.markdown('<div class="ctl-label">Search history</div>', unsafe_allow_html=True)
        q = st.text_input(
            "Search history",
            value=st.session_state["chat_search_q"],
            placeholder="Enter keywords; Use Prev/Next to jump",
            key="chat_search_q",
            label_visibility="collapsed",
        ).strip()

        # Prev / Next / Latest æŒ‰é’®æ”¾åœ¨åŒä¸€è¡Œ
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1.2], gap="small")

        with col_btn1:
            st.markdown('<div class="small-btn ctrl-group">', unsafe_allow_html=True)
            btn_prev = st.button("Prev", use_container_width=True, key="btn_prev")
            st.markdown('</div>', unsafe_allow_html=True)

        with col_btn2:
            st.markdown('<div class="small-btn ctrl-group">', unsafe_allow_html=True)
            btn_next = st.button("Next", use_container_width=True, key="btn_next")
            st.markdown('</div>', unsafe_allow_html=True)

        with col_btn3:
            st.markdown('<div class="small-btn ctrl-group">', unsafe_allow_html=True)
            btn_jump_latest = st.button("â¬‡ï¸ Latest", use_container_width=True, key="btn_latest")
            st.markdown('</div>', unsafe_allow_html=True)

    if btn_jump_latest:
        st.session_state["force_scroll_bottom"] = True

    # === æ„å»ºâ€œæ˜¾ç¤ºåˆ—è¡¨â€çš„ç´¢å¼•ï¼ˆæŒ‰æ¨¡å—è¿‡æ»¤ï¼Œåªæ˜¾ç¤ºâ€œAI(é€‰ä¸­æ¨¡å—)+å®ƒå‰é¢çš„å­¦ç”Ÿé—®â€ï¼‰ ===
    messages = st.session_state[chat_key]
    allowed = set(st.session_state["chat_filter_roles"])

    display_indices = []
    n = len(messages)


    def include_pair(ai_idx: int):
        """æŠŠ ai_idx åŠå…¶å‰é¢çš„æœ€è¿‘ä¸€æ¡ user åŠ å…¥æ˜¾ç¤º"""
        if 0 <= ai_idx < n and ai_idx not in display_indices:
            display_indices.append(ai_idx)
        # å¯»æ‰¾ ai ä¹‹å‰æœ€è¿‘çš„ä¸€æ¡ user
        j = ai_idx - 1
        while j >= 0 and messages[j]["role"] == "system":
            j -= 1
        if j >= 0 and messages[j]["role"] == "user" and j not in display_indices:
            display_indices.append(j)


    # 1) æ”¶é›†ç¬¦åˆæ¨¡å—çš„ AI å›å¤ä¸å…¶å‰é¢çš„ user
    for i, msg in enumerate(messages):
        if msg["role"] == "ai":
            module = msg.get("module", "AI")
            if module in allowed:
                include_pair(i)

    # 2) å¦‚æœæœ€åä¸€æ¡æ˜¯â€œç”¨æˆ·åˆšå‘çš„æ¶ˆæ¯â€ï¼ˆå¯èƒ½è¿˜æ²¡æ”¶åˆ° AIï¼‰ï¼Œä¹Ÿæ˜¾ç¤ºå®ƒ
    if n > 0 and messages[-1]["role"] == "user":
        if (n - 1) not in display_indices:
            display_indices.append(n - 1)

    # 3) æ’åºä¿æŒæ—¶é—´é¡ºåº
    display_indices.sort()

    # === è®¡ç®—æœç´¢å‘½ä¸­ï¼ˆä»…åœ¨â€œæ˜¾ç¤ºåˆ—è¡¨â€å†…æœç´¢ï¼‰ ===
    hits = []
    if q:
        q_lower = q.lower()
        for i in display_indices:
            content = str(messages[i].get("content", ""))
            if q_lower in content.lower():
                hits.append(i)

    # === å¤„ç† Next/Prev å¯¼èˆª ===
    if hits:
        if btn_next:
            st.session_state["search_pos"] = (st.session_state.get("search_pos", 0) + 1) % len(hits)
            st.session_state["scroll_to_msg_id"] = f"msg-{hits[st.session_state['search_pos']]}"
        if btn_prev:
            st.session_state["search_pos"] = (st.session_state.get("search_pos", 0) - 1) % len(hits)
            st.session_state["scroll_to_msg_id"] = f"msg-{hits[st.session_state['search_pos']]}"

    # å‘½ä¸­è®¡æ•°æç¤º
    if q:
        if hits:
            pos = (st.session_state.get('search_pos', 0) % len(hits)) + 1 if len(hits) else 0
            st.caption(f"ğŸ” Found {len(hits)} hit(s) â€” {pos}/{len(hits)}")
        else:
            st.caption("ğŸ” No hits")


    # ===== Markdown rendering (server-side) =====
    def render_markdown_to_html(md_text: str) -> str:
        """Render Markdown to safe HTML. Falls back to a minimal converter if libs are missing."""
        try:
            import markdown as md
            html_out = md.markdown(md_text, extensions=["fenced_code", "tables", "toc", "sane_lists"])
            try:
                import bleach
                allowed = bleach.sanitizer.ALLOWED_TAGS.union(
                    {"p", "pre", "code", "table", "thead", "tbody", "tr", "th", "td", "hr",
                     "h1", "h2", "h3", "h4", "h5", "h6", "ul", "ol", "li", "blockquote"}
                )
                return bleach.clean(html_out, tags=allowed, strip=True)
            except Exception:
                return html_out
        except Exception:
            # minimal fallback: keep bold / code / line breaks
            s = html.escape(md_text, quote=False)
            s = s.replace("**", "<b>").replace("`", "<code>")
            return s.replace("\n", "<br>")


    def highlight_after_rendered(html_text: str, q: str) -> str:
        if not q:
            return html_text
        # highlight matched query segments
        return re.sub(re.escape(q), lambda m: f"<mark>{html.escape(m.group(0))}</mark>",
                      html_text, flags=re.IGNORECASE)


    # === æ¸²æŸ“èŠå¤©ï¼ˆç»„ä»¶ç‰ˆï¼šiframe å†…å®Œå…¨å¯æ§ï¼‰ ===
    inner_html = ""
    for i, msg in enumerate(messages):
        if i not in display_indices:
            continue
        raw = str(msg.get("content", ""))
        rendered = render_markdown_to_html(raw)  # Markdown â†’ safe HTML
        content_html = highlight_after_rendered(rendered, q)  # å¯é€‰é«˜äº®
        if msg["role"] == "user":
            inner_html += f"<div class='bubble user-bubble' id='msg-{i}'>ğŸ‘¤ You ({user_id})<br>{content_html}</div>"
        elif msg["role"] == "ai":
            module = msg.get("module", "AI")
            css_class = {
                "Concept Learning": "concept",
                "Model Iteration": "model",
                "Strategy Review": "strategy"
            }.get(module, "")
            inner_html += f"<div class='bubble ai-bubble {css_class}' id='msg-{i}'>ğŸ¤– {module}<br>{content_html}</div>"
        elif msg["role"] == "system":
            inner_html += f"<div class='system' id='msg-{i}'>{content_html}</div>"

    _force = bool(st.session_state.get("force_scroll_bottom", False))
    target_id = st.session_state.get("scroll_to_msg_id", "")

    # ç”¨å®Œå³æ¸…ï¼ˆé¿å…ä¸‹æ¬¡é‡å¤è§¦å‘ï¼‰
    st.session_state["force_scroll_bottom"] = False
    st.session_state["scroll_to_msg_id"] = ""

    CHAT_HEIGHT = 500

    components.html(f"""
    <!DOCTYPE html>
    <html><head><meta charset="utf-8" />
    <style>
      html, body {{
        margin: 0; padding: 0; height: 100%; overflow: hidden;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial;
      }}
      .chat-wrapper {{
          background-color: #f5f5f5;
          padding: 12px;
          border-radius: 10px;
          height: {CHAT_HEIGHT}px;
          overflow-y: auto;
          display: flex;
          flex-direction: column;
          scroll-behavior: smooth;
          overscroll-behavior: contain;
          scrollbar-gutter: stable;
      }}
      .bubble {{
          max-width: 75%;
          padding: 8px 12px;
          margin: 6px;
          border-radius: 8px;
          word-wrap: break-word;
          font-size: 14px;
          line-height: 1.4;
      }}
      .user-bubble {{ background-color: #95ec69; margin-left: auto; text-align: right; }}
      .ai-bubble {{ margin-right: auto; text-align: left; }}
      .concept {{ background-color: #d0e6ff; }}
      .model {{ background-color: #ffe4b3; }}
      .strategy {{ background-color: #e6ccff; }}
      .system {{
          color: #555;
          text-align: center;
          font-size: 13px;
          font-style: italic;
          margin: 4px 0;
      }}
      .hit-focus {{
          outline: 2px solid #ffb703;
          transition: outline 1.2s ease-in-out;
      }}
      mark {{ padding: 0 2px; }}
      /* code/table styling for rendered Markdown */
  pre, code {{
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 12.5px;
  }}
  pre {{
    background: #f7f7f9;
    padding: 8px 10px;
    border-radius: 6px;
    overflow: auto;
  }}
  table {{ border-collapse: collapse; max-width: 100%; }}
  th, td {{ border: 1px solid #e5e7eb; padding: 4px 8px; font-size: 13px; }}
  blockquote {{ border-left: 3px solid #e5e7eb; margin: 6px 0; padding: 4px 8px; color:#444; }}
 
    </style>
    </head>
    <body>
      <div class="chat-wrapper" id="chat-box">{inner_html}</div>

  <script>
(function() {{
  const chatBox = document.getElementById('chat-box');
  if (!chatBox) return;

  // Python â†’ JS æ³¨å…¥ï¼ˆä¿æŒä¸å˜ï¼‰
  const FORCE  = {str(_force).lower()};
  const TARGET = {json.dumps(target_id)};

  // ä½¿ç”¨ user_id æ„é€ æœ¬åœ°å­˜å‚¨é”®ï¼›é¿å…ä½¿ç”¨æ¨¡æ¿å­—ç¬¦ä¸²ä»¥é˜² f-string è§£æ
  const STORAGE_KEY = "autoFollow:" + {json.dumps(user_id)};
  const SCROLL_KEY  = "scrollTop:"  + {json.dumps(user_id)};

  // --- auto-follow state (persisted via localStorage) ---
  function getAutoFollow() {{
    const v = localStorage.getItem(STORAGE_KEY);
    return (v === null) ? true : v === "1";
  }}
  function setAutoFollow(on) {{
    localStorage.setItem(STORAGE_KEY, on ? "1" : "0");
  }}

  // --- scrollTop persistence (sessionStorage) ---
  function saveScroll() {{
    try {{
      sessionStorage.setItem(SCROLL_KEY, String(chatBox.scrollTop));
    }} catch (e) {{}}
  }}
  function restoreScroll() {{
    try {{
      const v = sessionStorage.getItem(SCROLL_KEY);
      if (v !== null) {{
        const n = parseInt(v, 10);
        if (!Number.isNaN(n)) chatBox.scrollTop = n;
      }}
    }} catch (e) {{}}
  }}

  function isAtBottom() {{
    return chatBox.scrollTop + chatBox.clientHeight >= chatBox.scrollHeight - 40;
  }}
  function scrollToBottom(force) {{
    if (force || (getAutoFollow() && isAtBottom())) {{
      chatBox.scrollTop = chatBox.scrollHeight;
    }}
  }}
  function scrollToTarget(id) {{
    if (!id) return false;
    const el = document.getElementById(id);
    if (el) {{
      el.scrollIntoView({{ behavior: 'smooth', block: 'end' }});
      setAutoFollow(false);
      el.classList.add("hit-focus");
      setTimeout(() => el.classList.remove("hit-focus"), 1200);
      return true;
    }}
    return false;
  }}

  // Initial mount: prefer TARGET; else restore; apply FORCE if requested
  requestAnimationFrame(() => setTimeout(() => {{
    if (!scrollToTarget(TARGET)) {{
      if (!FORCE) restoreScroll();
      if (FORCE) setAutoFollow(true);
      scrollToBottom(FORCE);
    }}
  }}, 0));

  // Auto-follow when new nodes added (unless user scrolled up)
  const mo = new MutationObserver(() => {{
    if (getAutoFollow()) {{
      chatBox.scrollTop = chatBox.scrollHeight;
    }} else if (isAtBottom()) {{
      setAutoFollow(true);
    }}
  }});
  mo.observe(chatBox, {{ childList: true, subtree: true }});

  // User scroll behavior: scroll up â†’ disable follow; bottom â†’ enable follow
  let lastTop = chatBox.scrollTop;
  chatBox.addEventListener('scroll', () => {{
    saveScroll();
    const nowTop = chatBox.scrollTop;
    const delta  = nowTop - lastTop;
    lastTop = nowTop;
    if (delta < -10) {{
      setAutoFollow(false);
    }} else if (isAtBottom()) {{
      setAutoFollow(true);
    }}
  }});

  // Persist before unload (tab close / refresh)
  window.addEventListener('beforeunload', saveScroll);
}})();
</script>

    </body></html>
    """, height=CHAT_HEIGHT + 6, scrolling=False)

    # === è§’è‰²é€‰æ‹© ===
    role_help = {
        "Concept Learning": "Guide conceptual understanding.",
        "Model Iteration": "Assist with simulation and iteration.",
        "Strategy Review": "Review and improve strategies."
    }
    # --- Concise Mode toggle (EN) ---
    concise = st.toggle(
        "âœ‚ï¸ Concise mode (â‰¤6 lines + â‰¤2 questions)",
        value=True,
        help="Limit length and number of probing questions"
    )


    def get_prompt(role):
        style_guard = (
            "When replying, ALWAYS follow this structure:\n"
            "1) Key points (â‰¤4 bullet points)\n"
            "2) Evidence/Reasoning (â‰¤2 sentences)\n"
            "3) Next step (â‰¤1 actionable step)\n"
            "Ask at most 2 short questions.\n"
        )
        length_guard = "Hard cap: â‰¤6 lines total. Avoid meta talk." if concise else "No hard cap. Provide details when useful."
        sys = f"{roles[role]}\n{style_guard}{length_guard}\nHistorical Dialogue: {{history}}"
        return ChatPromptTemplate.from_messages([
            ("system", sys),
            ("user", "{question}")
        ])


    selected_role = st.selectbox(
        "ğŸ­ Choose AI Module",
        list(roles.keys()),
        index=0,
        key="role_select"
    )

    # âœ… ä¸å†åªæ˜¾ç¤ºæ‰€é€‰æ¨¡å—ç®€ä»‹ï¼›æ”¹ä¸ºå±•ç¤ºæ‰€æœ‰æ¨¡å—çš„ä¸€è¡Œç®€ä»‹
    st.markdown('<div class="ctl-label">Modules overview</div>', unsafe_allow_html=True)
    for r in roles:
        desc = role_descriptions.get(r) or role_help.get(r, "")
        # ä¸€è¡Œã€ç®€æ´ï¼šæ¨¡å—å + ç®€çŸ­è¯´æ˜
        st.caption(f"â€¢ **{r}** â€” {desc}")

    # ä¸‹é¢ä¿æŒåŸæœ‰çš„åˆ‡æ¢é€»è¾‘ï¼ˆåˆ‡æ¢è§’è‰²æ—¶æ»šåŠ¨åˆ°åº•éƒ¨ï¼‰
    if "prev_role" not in st.session_state:
        st.session_state["prev_role"] = selected_role
    if st.session_state["prev_role"] != selected_role:
        st.session_state["prev_role"] = selected_role
        st.session_state["force_scroll_bottom"] = True  # âœ… åˆ‡æ¢è§’è‰²åæ»šåˆ°æœ€æ–°

    # === è¾“å…¥æ¡† + å‘é€ & æ¸…é™¤æŒ‰é’®ï¼ˆåŒä¸€è¡Œï¼‰===
    st.markdown(
        """
        <style>
        .input-row {
            display: flex;
            align-items: center; /* âœ… å‚ç›´å±…ä¸­ */
            gap: 6px; /* âœ… è¾“å…¥æ¡†ä¸æŒ‰é’®é—´è· */
        }
        .text-input { flex: 1; } /* âœ… è‡ªé€‚åº”å¡«å…… */
        .send-btn button, .clear-btn button {
            height: 45px; /* âœ… é«˜åº¦å’Œè¾“å…¥æ¡†åŒ¹é… */
            width: 45px;  /* âœ… æ­£æ–¹å½¢æŒ‰é’® */
            border-radius: 8px;
            background-color: #4da6ff;
            color: white;
            font-size: 18px;
            border: none;
        }
        .send-btn button:hover, .clear-btn button:hover {
            background-color: #1a8cff;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # =========================
    # æ–¹æ¡ˆAï¼šåŠ¨æ€ key + epochï¼ˆå¹¶æ¸…ç†æ—§é”®ï¼‰
    # =========================
    if "question_buf" not in st.session_state:
        st.session_state["question_buf"] = ""
    if "input_epoch" not in st.session_state:
        st.session_state["input_epoch"] = 0

    # å½“å‰æ´»è·ƒçš„è¾“å…¥æ¡† key
    _active_key = f"text_area_input_{st.session_state['input_epoch']}"

    # æ¸…ç†å†å² widget stateï¼Œé˜²æ­¢é•¿æœŸè¿è¡Œå †ç§¯
    for k in list(st.session_state.keys()):
        if k.startswith("text_area_input_") and k != _active_key:
            try:
                del st.session_state[k]
            except Exception:
                pass

    st.markdown('<div class="input-row">', unsafe_allow_html=True)
    question = st.text_area(
        "ğŸ’¬",
        value=st.session_state.get("question_buf", ""),  # âœ… ä»ç„¶ä½¿ç”¨ value ä½œä¸ºåˆå§‹åŒ–/åç«¯å‚æ•°æº
        key=_active_key,  # âœ… åŠ¨æ€ keyï¼šæ¯æ¬¡é‡ç½®åˆ›å»ºæ–°ç»„ä»¶ï¼Œä½¿ value ç”Ÿæ•ˆ
        height=45,
        placeholder="Type a message...",
        label_visibility="collapsed"  # âœ… éšè— label
    )

    # å‘é€æŒ‰é’®
    submit = st.button("â†©ï¸", key="send_btn", help="Send message", use_container_width=False)

    st.markdown('</div>', unsafe_allow_html=True)


    # === æ’å…¥ä»¿çœŸæ•°æ®æŒ‰é’®ï¼ˆé£æ ¼ç»Ÿä¸€ï¼‰===
    insert_sim = st.button("ğŸ“¥ Insert Simulation Data", use_container_width=True)

    # === æ’å…¥ä»¿çœŸæ•°æ®é€»è¾‘ ===
    if insert_sim:
        m = st.session_state.get("camber_pct", 2.0) / 100
        p = st.session_state.get("p_pct", 40.0) / 100
        t = st.session_state.get("thickness_pct", 12.0) / 100
        alpha = st.session_state.get("alpha_deg", 5.0)
        rho = st.session_state.get("rho", 1.225)
        V = st.session_state.get("V", 10.0)
        chord = st.session_state.get("chord", 1.0)
        mu = st.session_state.get("mu", 1.8e-5)
        M = st.session_state.get("Mach", 0.0)
        Ncrit = st.session_state.get("Ncrit", 7.0)
        a_min, a_max = st.session_state.get("alpha_range", (0.0, 10.0))
        a_step = st.session_state.get("alpha_step", 1.0)

        naca_code = naca_code_from_mpt(m, p, t)
        Re = estimate_Re(rho, V, chord, mu)

        sim_text = (
            f"My current simulation results:\n"
            f"- NACA code: {naca_code}\n"
            f"- Re â‰ˆ {Re:.0f}, Mach={M}, Ncrit={Ncrit}\n"
            f"- Î± range: {a_min}Â° to {a_max}Â°, step={a_step}Â°\n"
            f"- Current Î±={alpha}Â°\n"
            f"- Parameters: camber={m:.2f}, thickness={t:.2f}, max_camber_pos={p:.2f}\n"
            f"- Fluid: Ï={rho}, V={V}, chord={chord}, Î¼={mu}\n"
            f"â¡ï¸ How can I improve my design strategy based on this?"
        )

        # è¦†ç›– value æºå¹¶åˆ‡æ¢åˆ°æ–° key â†’ ä¸‹è½®æ¸²æŸ“æ–‡æœ¬æ¡†æ˜¾ç¤ºä»¿çœŸå†…å®¹
        st.session_state["question_buf"] = sim_text
        st.session_state["input_epoch"] += 1
        st.rerun()

    # === å‘é€æ¶ˆæ¯é€»è¾‘ ===
    if submit and question.strip():
        student_question = question.strip()  # å½“å‰è¾“å…¥æ¡†çœŸå®å†…å®¹

        # 1) å‰ç«¯å…ˆæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state[chat_key].append({"role": "user", "content": student_question})

        # 2) å…ˆè½ç›˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆå³ä¾¿è¿˜æ²¡æœ‰ AI å›å¤ï¼‰
        try:
            requests.post(
                f"{BACKEND_URL}/save_conversation/",
                json={
                    "user_id": user_id,
                    "role": selected_role,
                    "student_question": student_question,
                    "ai_response": "",  # ç©ºä¹Ÿå†™å…¥
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                timeout=10
            )
        except Exception as e:
            st.warning(f"âš ï¸ Failed to save user message: {str(e)}")

        # 3) è°ƒç”¨ LLMï¼ˆLangGraphï¼‰
        # 3) Call LLM with retries (LangGraph)
        answer = ""
        try:
            history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state[chat_key]])
            state = {
                "role": selected_role,
                "history": history,
                "question": student_question,
            }
            # use retry helper
            answer = call_llm_with_retries(state, retries=3, base_delay=2.0)
        except Exception as e:
            st.error(f"LLM call failed: {e}")
            # 4) also log the error to backend for troubleshooting
            try:
                requests.post(
                    f"{BACKEND_URL}/save_conversation/",
                    json={
                        "user_id": user_id,
                        "role": selected_role,
                        "student_question": student_question,
                        "ai_response": f"[ERROR] {e}",
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    },
                    timeout=10
                )
            except Exception:
                pass

        # å¯é€‰çš„ç”¨æˆ·æç¤ºï¼šé‡è¯•åä»æ— æœ‰æ•ˆæ–‡æœ¬
        if not answer:
            st.info(
                "The AI returned no valid content after several attempts. Please retry in a moment or simplify your question.")

        # 5) âœ… æŠŠ AI å›å¤è¿½åŠ åˆ°å‰ç«¯ä¼šè¯ï¼Œå¹¶å†™å›åç«¯ï¼ˆä½ å½“å‰ç¼ºçš„å°±æ˜¯è¿™ä¸€å—ï¼‰
        if answer:
            st.session_state[chat_key].append({
                "role": "ai",
                "content": answer,
                "module": selected_role
            })
            try:
                requests.post(
                    f"{BACKEND_URL}/save_conversation/",
                    json={
                        "user_id": user_id,
                        "role": selected_role,
                        "student_question": student_question,
                        "ai_response": answer,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    },
                    timeout=10
                )
            except Exception as e:
                st.warning(f"âš ï¸ Failed to save AI reply: {e}")

        # 6) æ¸…ç©ºè¾“å…¥å¹¶åˆ·æ–°
        st.session_state["question_buf"] = ""
        st.session_state["input_epoch"] += 1
        st.session_state["force_scroll_bottom"] = True  # âœ… ä¸€å®šè¦åœ¨ rerun ä¹‹å‰ï¼
        st.rerun()

# ===== Right: Tabs =====
with col_main:
    tab_geo, tab_perf, tab_hist, tab_help, tab_admin = st.tabs([
        "ğŸ§© Geometry & Parameters", "ğŸ“ˆ Performance & Polars", "ğŸ—‚ï¸ History", "â“ Help", "ğŸ”‘ Admin"
    ])

    # === Geometry Tab ===
    with tab_geo:
        # ===== ä¸ŠåŠï¼šé¢„è§ˆ =====
        st.markdown("### Airfoil Preview", help=None)
        # è¯»å–å‚æ•°ï¼ˆä¿ç•™ä½ çš„åŸå€¼æ¥æºï¼‰
        m, p, t, alpha, rho, V, chord, mu, M, Ncrit, a_min, a_max, a_step, max_t_pos = \
            (st.session_state.get("camber_pct", 2.0) / 100,
             st.session_state.get("p_pct", 40.0) / 100,
             st.session_state.get("thickness_pct", 12.0) / 100,
             st.session_state.get("alpha_deg", 5.0),
             st.session_state.get("rho", 1.225),
             st.session_state.get("V", 10.0),
             st.session_state.get("chord", 1.0),
             st.session_state.get("mu", 1.8e-5),
             st.session_state.get("Mach", 0.0),
             st.session_state.get("Ncrit", 7.0),
             st.session_state.get("alpha_range", (0.0, 10.0))[0],
             st.session_state.get("alpha_range", (0.0, 10.0))[1],
             st.session_state.get("alpha_step", 1.0),
             st.session_state.get("tpos_pct", 30.0) / 100)

        xs, ys = gen_naca4(m, p, t)
        # >>> PATCH: ultra-safe, tighter Airfoil Preview (no tight/constrained/subplots_adjust)
        fig, ax = plt.subplots(figsize=(9.0, 4.8))  # ç¨å¤§ç”»å¸ƒ

        # ä¸»æ›²çº¿
        ax.plot(xs, ys, linewidth=2)

        # å®‰å…¨çš„ç«–çº¿ï¼ˆåªåœ¨ [0,1] å†…æ‰ç”»ï¼‰
        try:
            if 0.0 <= float(p) <= 1.0:
                ax.axvline(x=float(p), linestyle="--", linewidth=1.2, label="Max camber pos")
            if 0.0 <= float(max_t_pos) <= 1.0:
                ax.axvline(x=float(max_t_pos), linestyle=":", linewidth=1.2, label="Max thickness pos")
            ax.legend(loc="upper right", frameon=False, fontsize=10, borderaxespad=0.3, handlelength=2.4)
        except Exception:
            pass  # å›¾ä¾‹å‡ºé”™ç›´æ¥å¿½ç•¥ï¼Œä¸å½±å“ä¸»å›¾

        # è½´æ¯”ä¾‹ä¸æ ‡ç­¾
        ax.set_aspect("equal", "box")
        ax.set_xlabel("x/c", labelpad=2)
        ax.set_ylabel("y/c", labelpad=2)
        ax.set_title(f"NACA {naca_code_from_mpt(m, p, t)}", pad=4, fontsize=14)

        # â€”â€” åªåšâ€œå®‰å…¨è¾¹ç•Œâ€è®¡ç®—ï¼Œå…¨é¢ NaN/ç©ºæ•°ç»„ä¿æŠ¤ â€”â€” #
        mask = np.isfinite(xs) & np.isfinite(ys)
        if np.count_nonzero(mask) >= 2:
            xlo = float(np.nanmin(xs[mask]));
            xhi = float(np.nanmax(xs[mask]))
            ylo = float(np.nanmin(ys[mask]));
            yhi = float(np.nanmax(ys[mask]))
            xr = max(xhi - xlo, 1e-6)
            yr = max(yhi - ylo, 1e-6)
            # æ¨ªå‘å‡ ä¹è´´è¾¹ï¼›çºµå‘ä¿ç•™ ~6%
            ax.set_xlim(xlo - 0.01 * xr, xhi + 0.01 * xr)
            ax.set_ylim(ylo - 0.06 * yr, yhi + 0.06 * yr)
        else:
            # æç«¯æƒ…å†µä¸‹ç»™ä¸ªä¿åº•è¾¹ç•Œ
            ax.set_xlim(-0.01, 1.01)
            ax.set_ylim(-0.2, 0.2)

        # å»æ‰å¤šä½™è„Šçº¿ï¼Œå‡å°‘è§†è§‰ç•™ç™½
        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)

        # å…³é”®ï¼šç”¨å›ºå®šè½´çŸ©å½¢ä½ç½®â€œæ‰‹åŠ¨ç´§å‡‘â€ï¼Œé¿å…ä¸ä»»ä½•è‡ªåŠ¨å¸ƒå±€å†²çª
        # [left, bottom, width, height] in figure coordinates (0~1)
        # å¯ä»¥å†æŠŠ bottom/left ç¨å¾®å˜å°è®©å›¾æ›´â€œæ»¡â€ï¼Œä½†ä¸è¦ <0.05 ä»¥å…æ–‡å­—è¢«è£
        ax.set_position([0.08, 0.16, 0.90, 0.78])

        # è¾“å‡ºï¼ˆè‹¥ä½ æœ‰ fixed-plot å®¹å™¨å°±ä¿ç•™ï¼›æ²¡æœ‰ä¹Ÿå¯ä»¥ç›´æ¥ st.pyplotï¼‰
        with st.container():
            st.markdown('<div class="fixed-plot">', unsafe_allow_html=True)
            st.pyplot(fig, use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)

        Re = estimate_Re(rho, V, chord, mu)
        st.caption(f"Re â‰ˆ {Re:,.0f} Â· Î±={alpha:.1f}Â° Â· Ncrit={Ncrit:g} Â· M={M:g}")

        st.markdown("---")

        # ===== ä¸‹åŠï¼šç´§å‡‘å‚æ•°åŒºï¼ˆ3Ã—4 çš„æ …æ ¼ï¼Œå°½é‡å‹ç¼©ç«–å‘ç©ºé—´ï¼‰ =====
        st.markdown("### Parameters", help=None)
        # >>> PATCH: apply pending alpha (must run BEFORE creating the 'alpha_deg' slider anywhere)
        if "pending_alpha_deg" in st.session_state:
            try:
                st.session_state["alpha_deg"] = float(st.session_state.pop("pending_alpha_deg"))
            except Exception:
                st.session_state.pop("pending_alpha_deg", None)
        # >>> END PATCH

        # --- è¡Œ1ï¼šç¿¼å‹å‡ ä½•ï¼ˆç”¨ 4 åˆ—ï¼‰
        g1, g2, g3, g4 = st.columns(4)
        with g1:
            st.slider("Camber (%)", 0.0, 10.0, st.session_state.get("camber_pct", 2.0), 0.1, key="camber_pct")
        with g2:
            st.slider("Max camber pos (%)", 0.0, 100.0, st.session_state.get("p_pct", 40.0), 1.0, key="p_pct")
        with g3:
            st.slider("Thickness (%)", 5.0, 20.0, st.session_state.get("thickness_pct", 12.0), 0.1, key="thickness_pct")
        with g4:
            st.slider("Max thickness pos (%)", 0.0, 100.0, st.session_state.get("tpos_pct", 30.0), 1.0, key="tpos_pct")

        # --- è¡Œ2ï¼šæµåœºå‚æ•°ï¼ˆ4 åˆ—ï¼‰
        f1, f2, f3, f4 = st.columns(4)
        with f1:
            st.number_input("Ï (kg/mÂ³)", value=float(st.session_state.get("rho", 1.225)), key="rho")
        with f2:
            st.number_input("V (m/s)", value=float(st.session_state.get("V", 10.0)), key="V")
        with f3:
            st.number_input("Chord c (m)", value=float(st.session_state.get("chord", 1.0)),
                            min_value=0.05, step=0.05, key="chord")
        with f4:
            st.number_input("Î¼ (PaÂ·s)", value=float(st.session_state.get("mu", 1.8e-5)),
                            format="%.6e", key="mu")

        # --- è¡Œ3ï¼šæ±‚è§£è®¾ç½®ï¼ˆ4 åˆ—ï¼‰
        s1, s2, s3, s4 = st.columns(4)
        with s1:
            st.number_input("Mach", value=float(st.session_state.get("Mach", 0.0)),
                            min_value=0.0, max_value=0.3, step=0.01, key="Mach")
        with s2:
            st.number_input("Ncrit", value=float(st.session_state.get("Ncrit", 7.0)),
                            min_value=1.0, max_value=12.0, step=0.5, key="Ncrit")
        with s3:
            st.slider("Scan range Î± (Â°)", 0.0, 15.0, st.session_state.get("alpha_range", (0.0, 10.0)),
                      0.5, key="alpha_range")
        with s4:
            st.number_input("Î”Î± (Â°)", value=float(st.session_state.get("alpha_step", 1.0)),
                            min_value=0.1, max_value=2.0, step=0.1, key="alpha_step")

        # --- è¡Œ4ï¼šå½“å‰æ”»è§’ï¼ˆç‹¬å æˆ–ä¸å…¶ä»–æŒ‰é’®åŒè¡Œï¼‰
        h1, h2 = st.columns([2, 2])
        with h1:
            st.slider("Current Î± (Â°)", 0.0, 15.0, st.session_state.get("alpha_deg", 5.0), 0.5, key="alpha_deg")
        with h2:
            # è¿™é‡Œå¯é¢„ç•™æŒ‰é’®ä½ï¼Œæ¯”å¦‚â€œä¸€é”®æ’å…¥ä»¿çœŸå‚æ•°â€/â€œä¿å­˜å½“å‰å‡ ä½•â€ç­‰
            pass

    # === Performance Tab ===
    with tab_perf:
        st.subheader("Performance & Polars")
        m = st.session_state.get("camber_pct", 2.0) / 100
        p = st.session_state.get("p_pct", 40.0) / 100
        t = st.session_state.get("thickness_pct", 12.0) / 100
        alpha = st.session_state.get("alpha_deg", 5.0)
        rho = st.session_state.get("rho", 1.225)
        V = st.session_state.get("V", 10.0)
        chord = st.session_state.get("chord", 1.0)
        mu = st.session_state.get("mu", 1.8e-5)
        M = st.session_state.get("Mach", 0.0)
        Ncrit = st.session_state.get("Ncrit", 7.0)
        a_min, a_max = st.session_state.get("alpha_range", (0.0, 10.0))
        a_step = st.session_state.get("alpha_step", 1.0)
        naca_code = naca_code_from_mpt(m, p, t)
        Re = estimate_Re(rho, V, chord, mu)
        df_polar = run_xfoil_polar(naca_code, Re, M, Ncrit, float(a_min), float(a_max), float(a_step))

        # >>> PATCH: handle XFOIL failure (place right after df_polar = ...)
        if df_polar.empty:
            st.error(
                "XFOIL produced no valid polar. Check the Î± scan range/step, the Reynolds number magnitude, and Ncrit.")
            if st.button("Apply recommended scan: Î± = 0â€“10Â°, Î”Î± = 0.5Â°, Re â‰ˆ 3e5, Ncrit â‰ˆ 7",
                         key="btn_apply_recommended_scan", use_container_width=True):
                st.session_state["alpha_range"] = (0.0, 10.0)
                st.session_state["alpha_step"] = 0.5
                st.rerun()

            st.info("A simulated placeholder curve is shown below (non-physical). Adjust inputs and recompute.")
            df_polar = fallback_fake_polar(float(a_min), float(a_max), float(a_step))
        # >>> END PATCH

        idx_current = int(np.argmin(np.abs(df_polar["alpha"].values - alpha)))
        CL = float(df_polar.loc[idx_current, "CL"])
        CD = float(df_polar.loc[idx_current, "CD"])
        LD = CL / CD if CD > 1e-12 else np.nan

        df_valid = df_polar[df_polar["CD"] > 1e-12].copy()
        df_valid["L/D"] = df_valid["CL"] / df_valid["CD"]
        idx_opt = int(df_valid["L/D"].idxmax())
        alpha_opt = float(df_valid.loc[idx_opt, "alpha"])
        ld_max = float(df_valid.loc[idx_opt, "L/D"])

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("CL", f"{CL:.3f}")
        k2.metric("CD", f"{CD:.4f}")
        k3.metric("L/D", f"{LD:.1f}" if np.isfinite(LD) else "â€”")
        k4.metric("Î±* (best)", f"{alpha_opt:.1f}Â°")

        st.markdown(f"**Summary:** NACA {naca_code} Â· Re={Re:,.0f} Â· L/D_max={ld_max:.1f}")
        # >>> PATCH: current-Î± explanation + snap button (place right after Summary, BEFORE plotting)
        st.caption(
            "Current Î± is used to read/mark on charts (it does not change the solved polar). To include it, adjust the scan range.")
        if not df_polar.empty and "alpha" in df_polar:
            if st.button("Snap current Î± to nearest grid point", key="btn_snap_alpha", use_container_width=True):
                alpha_grid = df_polar["alpha"].to_numpy()
                snapped = float(alpha_grid[np.argmin(np.abs(alpha_grid - alpha))])
                # write to pending key; let tab_geo apply it BEFORE the slider is created
                st.session_state["pending_alpha_deg"] = snapped
                st.rerun()
        # >>> END PATCH

        tab1, tab2, tab3 = st.tabs(["CL vs Î±", "CD vs Î±", "L/D vs Î±"])


        def _vline(ax, a_cur):
            ax.axvline(a_cur, linestyle="--", linewidth=1.2)


        with tab1:
            fig_cl, ax_cl = plt.subplots(figsize=(8.0, 4.2))
            ax_cl.plot(df_polar["alpha"], df_polar["CL"], linewidth=2)
            _vline(ax_cl, alpha)
            ax_cl.set_xlabel("Î± (deg)");
            ax_cl.set_ylabel("CL");
            ax_cl.set_title("CL vs Î±")
            st.pyplot(fig_cl, use_container_width=True)

        with tab2:
            fig_cd, ax_cd = plt.subplots(figsize=(8.0, 4.2))
            ax_cd.plot(df_polar["alpha"], df_polar["CD"], linewidth=2)
            _vline(ax_cd, alpha)
            ax_cd.set_xlabel("Î± (deg)");
            ax_cd.set_ylabel("CD");
            ax_cd.set_title("CD vs Î±")
            st.pyplot(fig_cd, use_container_width=True)

        with tab3:
            fig2, ax2 = plt.subplots(figsize=(8.0, 4.2))
            ax2.plot(df_valid["alpha"], df_valid["L/D"], linewidth=2)
            _vline(ax2, alpha);
            _vline(ax2, alpha_opt)
            ax2.set_xlabel("Î± (deg)");
            ax2.set_ylabel("L/D");
            ax2.set_title("L/D vs Î± (with Î±* marker)")
            st.pyplot(fig2, use_container_width=True)

        # === Save Button ===
        if st.button("ğŸ’¾ Save this result", use_container_width=True):
            try:
                payload = {
                    "user_id": user_id,
                    "naca_code": naca_code,
                    "camber": m,
                    "thickness": t,
                    "max_camber_pos": p,
                    "alpha": alpha,
                    "rho": rho,
                    "velocity": V,
                    "chord": chord,
                    "mu": mu,
                    "re": Re,
                    "ncrit": Ncrit,
                    "mach": M,
                    "cl": CL,
                    "cd": CD,
                    "ld": LD if np.isfinite(LD) else 0.0,
                    "alpha_opt": alpha_opt,
                    "ld_max": ld_max,
                }
                r = requests.post(f"{BACKEND_URL}/save_airfoil/", json=payload, timeout=10)
                if r.status_code == 200:
                    st.success("âœ… Airfoil data saved to backend")
                else:
                    st.error(f"âŒ Save failed: {r.text}")
            except Exception as e:
                st.error(f"âš ï¸ Error when saving: {e}")

    # === History Tab ===
    with tab_hist:
        st.subheader("ğŸ“œ My History")

        # åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ Refresh History", use_container_width=True):
            st.session_state["refresh_history"] = True

        # é»˜è®¤ç¬¬ä¸€æ¬¡è¿›å…¥å°±åˆ·æ–°
        if "refresh_history" not in st.session_state:
            st.session_state["refresh_history"] = True

        df_hist = None
        if st.session_state["refresh_history"]:
            try:
                resp = requests.get(f"{BACKEND_URL}/export_airfoils/{user_id}", timeout=10).json()
                if resp:
                    df_hist = pd.DataFrame(resp)
                    st.dataframe(
                        df_hist[[
                            "id", "user_id", "naca_code", "camber", "thickness",
                            "max_camber_pos", "alpha", "rho", "velocity", "chord",
                            "mu", "re", "ncrit", "mach", "cl", "cd", "ld",
                            "alpha_opt", "ld_max", "timestamp"
                        ]],
                        use_container_width=True, height=400
                    )
                else:
                    st.info("No saved records yet.")
            except Exception as e:
                st.warning(f"âš ï¸ Backend fetch failed: {e}")

            # è‡ªåŠ¨åˆ·æ–°å®Œæˆåå…³é—­æ ‡å¿—ï¼Œä¸‹æ¬¡åªæœ‰ç‚¹åˆ·æ–°æŒ‰é’®æ‰ä¼šå†è¯·æ±‚
            st.session_state["refresh_history"] = False

        # âœ… å¦‚æœæœ‰æ•°æ®ï¼Œæä¾›å¯¼å‡ºæŒ‰é’®ï¼ˆå³ä¾¿æ²¡åˆ·æ–°è¿‡ä¹Ÿèƒ½ç”¨ï¼‰
        if df_hist is not None and not df_hist.empty:
            csv = df_hist.to_csv(index=False).encode("utf-8")
            st.download_button(
                label="ğŸ“¥ Download My History (CSV)",
                data=csv,
                file_name=f"{user_id}_history.csv",
                mime="text/csv",
                use_container_width=True
            )
        # === Help Tab ===
        with tab_help:
            st.markdown("## Help Center")
            st.caption("AI-Enhanced Airfoil Design & Learning Lab â€” Quick reference and troubleshooting")

            st.markdown("### Overview")
            st.markdown("""
        This web app is an **AI-assisted airfoil design and learning environment** combining:  
        1) **Geometry preview & parameter controls** (NACA 4-digit),  
        2) **XFOIL polar analysis** (CL/CD/CM and L/D), and  
        3) **Role-based tutoring** for concept learning, model iteration, and strategy review.
        """)

            st.markdown("### Quick Start")
            st.markdown("""
        1. **Set parameters** in **Geometry & Parameters** (camber `m%`, max camber position `p%`, thickness `t%`, flow & solver settings).  
        2. Switch to **Performance & Polars** to compute polars and view **CL**, **CD**, **L/D**, and **Î±\***.  
        3. In the **Dialogue** (left), pick a role in **ğŸ­ Choose AI Module**, ask a question, or click **ğŸ“¥ Insert Simulation Data** to auto-paste your current settings, then discuss improvements with the AI.  
        4. Use **History** to view or export saved runs and **Restore historical dialogue** to reload past chats (per user).
        """)

            st.markdown("### Page Layout")
            st.markdown("""
        - **Left column**: Dialogue (role selection, search, history restore, input & send).  
        - **Right column**: Tabs for **Geometry & Parameters**, **Performance & Polars**, **History**, **Help**, and **Admin** (admin only).
        """)

            with st.expander("AI Roles (when to use which)"):
                st.markdown("""
        - **Concept Learning** â€” Clarify core concepts (e.g., lift coefficient, stall, Reynolds number). Use a **guiding** tone, ask probing questions.  
        - **Model Iteration** â€” Plan experiments, scan parameters (Î± range/step, Re, Ncrit) and compare outcomes.  
        - **Strategy Review** â€” Critically evaluate your approach (claimâ€“evidenceâ€“warrant), surface gaps and next steps.
        """)

            with st.expander("Geometry & Parameters (what each control means)"):
                st.markdown("""
        - **NACA 4-digit** (`mpt` â†’ `m%`, `p/10`, `t%`): `m` camber, `p` chordwise location of max camber, `t` thickness.  
        - **Flow**: Ï (density), **V** (velocity), **c** (chord), **Î¼** (dynamic viscosity). Reynolds number `Re = ÏVc/Î¼`.  
        - **Solver**: **Mach** (typically â‰¤ 0.3 for incompressible assumptions), **Ncrit** (transition criterion, e.g., 5â€“9 for typical wind-tunnel atmospheres).  
        - **Scan**: Î± range `[Î±_min, Î±_max]` and step `Î”Î±` for **ASEQ** scanning; use a smaller `Î”Î±` for finer L/D peaks.
        """)

            with st.expander("Performance & Polars (how to read the plots)"):
                st.markdown("""
        - **CL(Î±)**, **CD(Î±)**, **CM(Î±)** are computed from XFOIL polars.  
        - **L/D** helps locate efficient angles; the app highlights **Î±\*** where L/D is maximal in the scanned range.  
        - If XFOIL returns no valid data, the app will show a **simulated fallback** curve (for UI continuity). Prefer fixing inputs to get physical results.
        """)

            with st.expander("Dialogue & Data (good practices)"):
                st.markdown("""
        - Use **ğŸ“¥ Insert Simulation Data** to paste the current setup into the chat, then ask the AI to critique or suggest iterations.  
        - Phrase prompts for **reasoning**, e.g., *â€œIf I increase `t%` while keeping `Re` fixed, what trade-offs appear in stall and L/D?â€*  
        - **History** tab: inspect, refresh, and export your saved runs (CSV). **Admin** can export all usersâ€™ data.
        """)

            st.markdown("### Methodological Guidance")
            st.markdown("""
        - Treat the AI as a **Socratic partner**: ask â€œwhy/howâ€ questions, test hypotheses, and compare runs under controlled changes.  
        - For argumentation, structure your notes as **Claimâ€“Evidenceâ€“Warrant** (and add Qualifiers/Rebuttals when applicable).  
        - Keep **Re**, **Î± range**, **Î”Î±**, **Ncrit** explicit in your lab notes to ensure **reproducibility**.
        """)

            st.markdown("### FAQ")
            st.markdown("""
        **Q1. My input remains in the box after sending.**  
        The app clears after submission; if you still see text, refresh the page to resync the widget state.

        **Q2. XFOIL returns no polar or `polar.out` is empty.**  
        Check Î± range/step and `Re` magnitude; try moderate **Ncrit** (e.g., 7) and ensure `xfoil.exe` exists in the app root on Windows. If geometry is extreme (very high camber/thickness or tiny `Re`), start with gentler values.

        **Q3. L/D looks strange or NaN.**  
        This occurs if **CD â‰ˆ 0** or data is sparse. Reduce `Î”Î±`, widen the scan, or adjust `Re`/`Ncrit` for a stable polar.

        **Q4. â€œAddress already in useâ€ on port 8000/8501.**  
        Stop previous processes using those ports (Windows: Task Manager or `netstat` + `taskkill`; Linux/macOS: `lsof -i :PORT` then `kill -9 PID`).
        """)

            st.markdown("### Troubleshooting Checklist")
            st.markdown("""
        - âœ… **Executable**: On Windows, ensure **`xfoil.exe`** is in the project root.  
        - âœ… **Ranges**: Use reasonable **Î±** ranges (e.g., 0Â°â€“10Â°) and `Î”Î±` (0.5Â°â€“1Â°) to start.  
        - âœ… **Reynolds**: Verify `Re = ÏVc/Î¼` is not pathologically small/large for your case.  
        - âœ… **Ncrit**: Start near 7; move Â±2 if convergence is poor.  
        - âœ… **Fallback**: If you see a fallback curve, it means no valid XFOIL dataâ€”adjust inputs and recompute.
        """)

            st.markdown("### Notes on Ethics & Data")
            st.markdown("""
        - Use the system for **learning and research**; cite results appropriately in coursework or publications.  
        - Dialogue logs and run data may be stored for analysis; anonymize when required by your IRB/ethics policy.
        """)

            st.info("This Help is adapted from your uploaded quick-guide and refined for clarity and research use. "
                    "For classroom deployment, you may extend with course-specific rubrics and examples. "
                    "Source: internal guide. "
                    ":contentReference[oaicite:0]{index=0}")

    # === Admin Panel ===
    with tab_admin:
        if is_admin:
            st.success("âœ… Logged in as Admin")
            st.markdown("### Export All Data")

            # Conversations
            if st.button("ğŸ“¥ Download All Conversations (CSV)", use_container_width=True):
                try:
                    resp = requests.get(f"{BACKEND_URL}/admin/export_all_conversations", timeout=20)
                    if resp.status_code == 200:
                        csv = resp.content
                        st.download_button(
                            label="â¬‡ï¸ Save Conversations",
                            data=csv,
                            file_name="all_conversations.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    else:
                        st.error(f"âŒ Failed: {resp.text}")
                except Exception as e:
                    st.error(f"âš ï¸ Error fetching conversations: {e}")

            # Airfoils
            if st.button("ğŸ“¥ Download All Airfoils (CSV)", use_container_width=True):
                try:
                    resp = requests.get(f"{BACKEND_URL}/admin/export_all_airfoils", timeout=20)
                    if resp.status_code == 200:
                        csv = resp.content
                        st.download_button(
                            label="â¬‡ï¸ Click here to save Airfoils",
                            data=csv,
                            file_name="all_airfoils.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    else:
                        st.error(f"âŒ Failed: {resp.text}")
                except Exception as e:
                    st.error(f"âš ï¸ Error fetching airfoils: {e}")
        else:
            st.warning("Enter the correct admin password to access this panel.")
